{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a634ae8645b8ff68cae9d5c16e3ec1fc",
     "grade": false,
     "grade_id": "cell-13a9a086fe9a8c80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-danger\" style=\"color:black\"><b>Running ML-LV Jupyter Notebooks:</b><br>\n",
    "    <ol>\n",
    "        <li>Make sure you are running all notebooks using the <code>adv_ai</code> kernel.\n",
    "        <li><b>It is very important that you do not create any additional files within the weekly folders on CSCT cloud.</b> Any additional files, or editing the notebooks with a different environment may prevent submission/marking of your work.</li>\n",
    "            <ul>\n",
    "                <li>NBGrader will automatically fetch and create the correct folders files for you.</li>\n",
    "                <li>All files that are not the Jupyter notebooks should be stored in the 'ML-LV/data' directory.</li>\n",
    "            </ul>\n",
    "        <li>Please <b>do not pip install</b> any python packages (or anything else). You should not need to install anything to complete these notebooks other than the packages provided in the Jupyter CSCT Cloud environment.</li>\n",
    "    </ol>\n",
    "    <b>If you would like to run this notebook locally you should:</b><br>\n",
    "    <ol>\n",
    "        <li>Create an environment using the requirements.txt file provided. <b>Any additional packages you install will not be accessible when uploaded to the server and may prevent marking.</b></li>\n",
    "        <li>Download a copyÂ  of the notebook to your own machine. You can then edit the cells as you wish and then go back and copy the code into/edit the ones on the CSCT cloud in-place.</li>\n",
    "        <li><b>It is very important that you do not re-upload any notebooks that you have edited locally.</b> This is because NBGrader uses cell metadata to track marked tasks. <b>If you change this format it may prevent marking.</b></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2a323cf48e33efacebbe56c41e57e73",
     "grade": false,
     "grade_id": "cell-de83c5a747ff5bf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Practical 1: Data Acquisition\n",
    "\n",
    "Machine learning algorithms require **a lot** of data, typically the more the better. Of course, there are many pre-existing datasets available and often used for learning purposes, or as benchmarks for particular NLP tasks, such as SQuAD and GLUE. These datasets are often well studied and can simply be downloaded and used with minimal pre-processing.\n",
    "\n",
    "However, applying NLP to a new problem or task will often require data to be gathered, processed and if ground-truth labels are needed (e.g. for supervised learning), annotated. Indeed, the process of data acquisition can often be one of the most time consuming and labour intensive of any NLP project. Depending on the problem the data could come from existing documents, created by hand, or we can use the largest source of information - the internet. [Web scraping](https://en.wikipedia.org/wiki/Web_scraping) allows us to extract data from websites, so it is possible to obtain huge amounts of information. In fact, scraping was used to extract the ~500 billion token datasets used to train some of the largest state-of-the-art (SOTA) language models, like GPT-3 ([Brown, T.B., et al., 2020](https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)).\n",
    "\n",
    "In this practical we will use web scraping to gather some movie reviews written by IMDB users. Specifically, from [The Best Worst Movies](https://www.imdb.com/list/ls003589177/) list. Then, we will annotate these reviews with a sentiment, positive or negative. In later practicals we will learn how to process this data and then build a model to classify the sentiment.\n",
    "\n",
    "The objectives of this practical are:\n",
    "1. Understand the process of web scraping to obtain data\n",
    "\n",
    "2. Use existing tools to annotate data and manage data versioning\n",
    "\n",
    "3. Consider the legal and ethical implications of web scraping and data acquisition in general\n",
    "\n",
    "4. Produce a set of IMDB user reviews, annotated with positive or negative sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5390cf29c69caf8b2e64a5a72c260fda",
     "grade": false,
     "grade_id": "cell-cabe3618615481fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.0 Import libraries\n",
    "\n",
    "Most of these Python libraries you should already be familiar with. For the web scraping we will use two specifically:\n",
    "\n",
    "1. Requests - allows us to make HTTP requests for web pages i.e. ask a web server to send a web page and its data.\n",
    "\n",
    "2. [Beautiful Soup 4 (bs4)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - is a Python library for parsing and navigating HTML files. This makes the job of finding the data we want, from within a received page, much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Get the status of NBgrader (for skipping cell execution while validating/grading)\n",
    "grading = True if os.getenv('NBGRADER_EXECUTION') else False\n",
    "\n",
    "# Get the project directory (should be in ML-LV)\n",
    "path = ''\n",
    "while os.path.basename(os.path.abspath(path)) != 'ML-LV':\n",
    "    path = os.path.abspath(os.path.join(path, '..'))\n",
    "\n",
    "# Set the directory to the data folder (should be in ML-LV/data/imdb)\n",
    "data_dir = os.path.join(path, 'data', 'imdb')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Set the directory to the shared dataset folder (should be in shared/datasets/imdb)\n",
    "dataset_dir = os.path.join(path, '..', 'shared', 'datasets', 'imdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e642068a83938529d6da28b6a6a4ef4",
     "grade": false,
     "grade_id": "cell-fdae0170ec74c1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Get a list of movie names and the URL to their IMDB page\n",
    "\n",
    "As previously stated, we will be getting reviews for movies in IMDB's curated list of [The Best Worst Movies](https://www.imdb.com/list/ls003589177/). If you follow the link you should can see the list of movies for yourself.\n",
    "\n",
    "The process of web scraping simply involves requesting a web page from a server and then extracting the data we are interested in. However, in reality we may not know the exact URL, or we may wish to scrape many web pages at once. In this case we have a list of movies and we need to find the links to each of their IMDB pages. Unfortunately IMDB would prefer we use their API for retrieving data, so to simplify the process we will use a list of movies stored in CSV format. The following demonstrates how to scrape the first review of the first movie in the list.\n",
    "\n",
    "1. First we will load the .csv file containing the movie titles and their URL's.\n",
    "\n",
    "2. Next we send a request for the first movies review page. The response is the same information used by your browser to render the page. If you uncomment `print(response.content)` you can see the full response (it's pretty horrible) and `print(response.status_code)` tells us if it returned correctly or if there was an error.\n",
    "\n",
    "3. Then we use beautiful soup to parse the response into a more manageable object ('soup'). Again, if you uncomment `print(soup.prettify())` you can see what this looks like (better, but still horrible).\n",
    "\n",
    "4. Now we can begin to parse the page's data to find the reviews titles and contents. If you opened the page in your browser you can right click on a movie title and select 'inspect'. This will open the developer console and you should see that each review title is actually in an an `h3` tag (of class `ipc-title__text`) and the review body is held within a `div` tag (of class `ipc-html-content-inner-div`). So we can use bs4 to get a list of all the titles and review contents of these types.\n",
    "\n",
    "5. Finally, we also replace `br` tags with a space to preserve separation in the original text text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Best and Worst Movies\n",
      "                              Title                                    URL\n",
      "0  Superman IV: The Quest for Peace  https://www.imdb.com/title/tt0094074/\n",
      "1   Monsters Crash the Pajama Party  https://www.imdb.com/title/tt0059466/\n",
      "2                    Batman Forever  https://www.imdb.com/title/tt0112462/\n",
      "3                    Batman & Robin  https://www.imdb.com/title/tt0118688/\n",
      "4                               Ape  https://www.imdb.com/title/tt0074148/\n",
      "There are 134 in the list.\n",
      "First review title: Such a shame!\n",
      "First review content: SUPERMAN IV: THE QUEST FOR PEACE  OK... so everyone knows that this is the worst Superman movie ever made... but if you have not seen it in a while, you should watch it.  It is still pretty rubbish, but it is not as bad as I remember.  The story is not that bad... Superman rids planet Earth of all the nuclear weapons, and in doing so unknowingly creates a super villain named Nuclear Man thanks to arch rival Lex Luthor.  The movie does star all the original cast, which surprised me. I knew Christopher Reeve was in it... and after reading his autobiography now know why. He said in the book that he only made it because the film studio wanted to make it and they said to him that they would only finance another movie he wanted to make if he made Superman IV. I will quote what he said in his book... \"The less said about Superman IV the better.\"  Gene Hackman returns as Lex Luthor & Margot Kidder is back as Lois Lane. They all did good jobs as always, although Margot was a bit unsure in places. The other supporting cast were not great. Mariel Hemingway played the new boss of the Daily Planet. She was awful... not a great actress in this I'm afraid. But she was not the worst. Mark Pillow played Nuclear Man. Absolutely terrible. His acting was definitely the worst of the whole quadrilogy.  The effects in this film were so bad. You could see that the budget of this film was so much less than the other 3 movies made. Superman flying was so bad that Flash Gordon was more convincing... and speaking of Flash Gordon... Nuclear Man looked like him... but more camp! Nuclear Mans outfit was embarrassing... it was not much of a super villains outfit. It honestly was just a bad character through and through.  There are also some really bad scenes... there was a scene where a large chuck of the Great Wall of China gets destroyed and Superman fixes it just by looking at it and using some dodgy blue eye lasers. What the hell? Terrible. Also, there is a scene where Nuclear Man kidnaps a Lacy and takes her into space... WHAT? He drags her to space and not only does she not scream or even say anything, but she can breathe fine in space... erm... really? I know Superman was never meant to be realistic, but that is too much!  When I was a kid I was a big fan of the Superman movies... but I think my parents protected me from this disappointment, because I don't remember this film at all... I didn't see this film until I was an adult. Haha. Thanks Mum.  I will give this film 5 out of 10.  It's a shame about this film... it was a very disappointing ending to Christopher Reeves Superman career. But no matter what he will always be a legend.  For more reviews, please like my Facebook page:  https://www.facebook.com/pages/Ordinary-Person-Movie- Reviews/456572047728204?ref=hl\n"
     ]
    }
   ],
   "source": [
    "# Load the list of best and worst movies\n",
    "movie_list = pd.read_csv(os.path.join(dataset_dir, 'imdb_best_worst_list.csv'))\n",
    "\n",
    "# Drop the columns that are not needed\n",
    "movie_list = movie_list[['Title', 'URL']]\n",
    "print(\"IMDB Best and Worst Movies\")\n",
    "print(movie_list.head())\n",
    "print(f\"There are {movie_list.shape[0]} in the list.\")\n",
    "\n",
    "# Send http request to get the review page\n",
    "# Appending \"reviews/\" to the movie url gets the review page\n",
    "header = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/131.0.0.0 Safari/537.36'}\n",
    "response = requests.get(movie_list['URL'][0] + 'reviews/', headers=header)\n",
    "# print(response.status_code)\n",
    "# print(response.content)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "\n",
    "# Get the titles of the first review\n",
    "review_titles = soup.find_all('h3', {'class': 'ipc-title__text'})\n",
    "titles = [t.text for t in review_titles]\n",
    "print(f\"First review title: {titles[0]}\")\n",
    "\n",
    "# Get the text of the first review\n",
    "review_contents = soup.find_all('div', {'class': 'ipc-html-content-inner-div'})\n",
    "# Replace the <br> tags with spaces\n",
    "for c in review_contents:\n",
    "    for br in c.find_all('br'):\n",
    "        br.replace_with(' ')\n",
    "reviews = [c.text for c in review_contents]\n",
    "print(f\"First review content: {reviews[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddcfe796844ea4672a132b3dc9a51cc8",
     "grade": false,
     "grade_id": "cell-a23874fffcccda70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 Get the user reviews\n",
    "\n",
    "Now that we have the links for each movie we can get their reviews. As you might expect, the movies in this list are quite controversial. For our purposes this means we will should have more balance between the sentiment classes. To keep things manageable we'll get 2 random review titles from each of the first 50 movies, for a nice even total of 100.\n",
    "\n",
    "The process is similar to the previous step:\n",
    "\n",
    "1. Loop over each movie and request its review page (movie_url + \"reviews/\").\n",
    "\n",
    "2. Get the titles of the reviews and also the main texts.\n",
    "\n",
    "3. Store these in a list of dictionaries, along with a unique review id.\n",
    "\n",
    "4. Create a Dataframe to hold the movie id, name, url, review title and empty sentiment, then save as .csv.\n",
    "\n",
    "<div class=\"alert alert-success\" style=\"color:black\"><b>Note:</b> The review page only shows the first 25 reviews.<br>\n",
    "We could use pagination to get the rest, but let's just stick with 25 for now.<br>\n",
    "\n",
    "<b>This may take a few minutes to complete!</b>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\" style=\"color:black\"><b>Legality of Web Scraping:</b> There are all kinds of <a href=\"https://www.blog.datahut.co/post/is-web-scraping-legal\"> legal and ethical considerations</a> surrounding web scraping, including copyright, scraping non-public data, or data behind a login, such as Facebook or Linkedin.<br>\n",
    "\n",
    "Notice that there is a time delay added after each movie request has been processed? This is to slow down the number of requests per second and prevent repeated requests overloading the server, or at least creating unnecessary traffic. Excessive 'crawl rates' could violate \"trespass to chattels\" law, though for this use case it is unlikely. Still, it is worth being polite while scraping.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting reviews for Superman IV: The Quest for Peace at https://www.imdb.com/title/tt0094074/\n",
      "Getting reviews for Monsters Crash the Pajama Party at https://www.imdb.com/title/tt0059466/\n",
      "Getting reviews for Batman Forever at https://www.imdb.com/title/tt0112462/\n",
      "Getting reviews for Batman & Robin at https://www.imdb.com/title/tt0118688/\n",
      "Getting reviews for Ape at https://www.imdb.com/title/tt0074148/\n",
      "Getting reviews for Birdemic: Shock and Terror at https://www.imdb.com/title/tt1316037/\n",
      "Getting reviews for Glen or Glenda at https://www.imdb.com/title/tt0045826/\n",
      "Getting reviews for Space Thunder Kids at https://www.imdb.com/title/tt1910621/\n",
      "Getting reviews for Captain America at https://www.imdb.com/title/tt0103923/\n",
      "Getting reviews for The Fantastic Four at https://www.imdb.com/title/tt0109770/\n",
      "Getting reviews for The Man Who Saves the World at https://www.imdb.com/title/tt0182060/\n",
      "Getting reviews for The Super Inframan at https://www.imdb.com/title/tt0073168/\n",
      "Getting reviews for Laserblast at https://www.imdb.com/title/tt0077834/\n",
      "Getting reviews for Troll 2 at https://www.imdb.com/title/tt0105643/\n",
      "Getting reviews for Contamination .7 at https://www.imdb.com/title/tt0106620/\n",
      "Getting reviews for Quest for the Mighty Sword at https://www.imdb.com/title/tt0100448/\n",
      "Getting reviews for Masters of the Universe at https://www.imdb.com/title/tt0093507/\n",
      "Getting reviews for The Screaming Skull at https://www.imdb.com/title/tt0052169/\n",
      "Getting reviews for Mortal Kombat: Annihilation at https://www.imdb.com/title/tt0119707/\n",
      "Getting reviews for The Lost Skeleton of Cadavra at https://www.imdb.com/title/tt0307109/\n",
      "Getting reviews for The Lost World at https://www.imdb.com/title/tt0054038/\n",
      "Getting reviews for Sherlock Holmes at https://www.imdb.com/title/tt1522835/\n",
      "Getting reviews for The Galaxy Invader at https://www.imdb.com/title/tt0089185/\n",
      "Getting reviews for Laser Mission at https://www.imdb.com/title/tt0099978/\n",
      "Getting reviews for Plan 9 from Outer Space at https://www.imdb.com/title/tt0052077/\n",
      "Getting reviews for Super Mario Bros. at https://www.imdb.com/title/tt0108255/\n",
      "Getting reviews for Violent Shit at https://www.imdb.com/title/tt0094271/\n",
      "Getting reviews for Werewolves on Wheels at https://www.imdb.com/title/tt0067972/\n",
      "Getting reviews for Monster a-Go Go at https://www.imdb.com/title/tt0059464/\n",
      "Getting reviews for Messalina, Messalina at https://www.imdb.com/title/tt0076388/\n",
      "Getting reviews for Santa Claus at https://www.imdb.com/title/tt0053241/\n",
      "Getting reviews for Santa Claus Conquers the Martians at https://www.imdb.com/title/tt0058548/\n",
      "Getting reviews for Highlander II: The Quickening at https://www.imdb.com/title/tt0102034/\n",
      "Getting reviews for Battlefield Earth at https://www.imdb.com/title/tt0185183/\n",
      "Getting reviews for An Alan Smithee Film: Burn Hollywood Burn at https://www.imdb.com/title/tt0118577/\n",
      "Getting reviews for The Room at https://www.imdb.com/title/tt0368226/\n",
      "Getting reviews for Alone in the Dark at https://www.imdb.com/title/tt0369226/\n",
      "Getting reviews for Dracula (The Dirty Old Man) at https://www.imdb.com/title/tt0064255/\n",
      "Getting reviews for Ninja the Protector at https://www.imdb.com/title/tt0199861/\n",
      "Getting reviews for Dungeons & Dragons at https://www.imdb.com/title/tt0190374/\n",
      "Getting reviews for Beastmaster 2: Through the Portal of Time at https://www.imdb.com/title/tt0101412/\n",
      "Getting reviews for Mystics in Bali at https://www.imdb.com/title/tt0097942/\n",
      "Getting reviews for The Giant Claw at https://www.imdb.com/title/tt0050432/\n",
      "Getting reviews for Nekromantik at https://www.imdb.com/title/tt0093608/\n",
      "Getting reviews for Godzilla vs. Hedorah at https://www.imdb.com/title/tt0067148/\n",
      "Getting reviews for The Manitou at https://www.imdb.com/title/tt0077904/\n",
      "Getting reviews for Godzilla vs. Megalon at https://www.imdb.com/title/tt0070122/\n",
      "Getting reviews for Tarantula at https://www.imdb.com/title/tt0048696/\n",
      "Getting reviews for Exorcist II: The Heretic at https://www.imdb.com/title/tt0076009/\n",
      "Getting reviews for Grunt! at https://www.imdb.com/title/tt0085625/\n"
     ]
    }
   ],
   "source": [
    "if not grading:\n",
    "    # Let's get 2 random reviews for a subset of 50 movies\n",
    "    # Alternatively you could get all movies (time consuming)\n",
    "    num_movies, num_reviews = 50, 2\n",
    "    movie_reviews = []\n",
    "\n",
    "    for movie_index in range(num_movies):\n",
    "        # Get the movie name and url\n",
    "        movie_name = movie_list['Title'][movie_index]\n",
    "        movie_url = movie_list['URL'][movie_index]\n",
    "        print(f\"Getting reviews for {movie_name} at {movie_url}\")\n",
    "  \n",
    "        # Send http request to get the review page\n",
    "        # Appending \"reviews?\" to the movie url gets the review page\n",
    "        header = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/131.0.0.0 Safari/537.36'}\n",
    "        response = requests.get(movie_url + 'reviews/', headers=header)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Get the review titles\n",
    "        review_titles = soup.find_all('h3', {'class': 'ipc-title__text'})\n",
    "        titles = [t.text for t in review_titles]\n",
    "\n",
    "        # Get the text of each review\n",
    "        review_contents = soup.find_all('div', {'class': 'ipc-html-content-inner-div'})\n",
    "        # Replace the <br> tags with spaces\n",
    "        for c in review_contents:\n",
    "            for br in c.find_all('br'):\n",
    "                br.replace_with(' ')\n",
    "        reviews = [c.text for c in review_contents]\n",
    "\n",
    "        # Add to the list of reviews\n",
    "        for i, (title, review) in  random.sample(list(enumerate(zip(titles, reviews))), k=num_reviews):\n",
    "            id = str(i) + '-' + movie_url.split('/')[-2] # Create unique review id from the movie id\n",
    "            movie_reviews.append({'id': id,'name': movie_name, 'url': movie_url, 'title': title, 'review': review})\n",
    "\n",
    "        # Add a time delay to prevent excessive requests\n",
    "        time.sleep(random.randint(2, 5))\n",
    "\n",
    "    # Create a dataframe from the list of reviews and add an empty sentiment column\n",
    "    reviews_df = pd.DataFrame(movie_reviews)\n",
    "    reviews_df['sentiment'] = None\n",
    "    \n",
    "    # Save to csv\n",
    "    reviews_df.to_csv(os.path.join(data_dir, 'imdb_reviews_raw.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62fc139f4edde52959a413c2f2329a5d",
     "grade": false,
     "grade_id": "cell-e7f3ef2c209e1e9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If that has all worked correctly the following should load your 'raw' IMDB review file and show there are 100 reviews, with 6 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12-tt0094074</td>\n",
       "      <td>Superman IV: The Quest for Peace</td>\n",
       "      <td>https://www.imdb.com/title/tt0094074/</td>\n",
       "      <td>Even Superman couldn't save this one!</td>\n",
       "      <td>There is a new nuclear arms race underway. Sup...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5-tt0094074</td>\n",
       "      <td>Superman IV: The Quest for Peace</td>\n",
       "      <td>https://www.imdb.com/title/tt0094074/</td>\n",
       "      <td>The Paradoxical Son...</td>\n",
       "      <td>Superman IV: The Quest for Peace is a good mov...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-tt0059466</td>\n",
       "      <td>Monsters Crash the Pajama Party</td>\n",
       "      <td>https://www.imdb.com/title/tt0059466/</td>\n",
       "      <td>Horrible movie, but great DVD!</td>\n",
       "      <td>Very odd and very short color film that tries ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-tt0059466</td>\n",
       "      <td>Monsters Crash the Pajama Party</td>\n",
       "      <td>https://www.imdb.com/title/tt0059466/</td>\n",
       "      <td>This film manages to be both fun and amazingly...</td>\n",
       "      <td>The acting, costumes and dialog for \"Monsters ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-tt0112462</td>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>https://www.imdb.com/title/tt0112462/</td>\n",
       "      <td>Better than most people remember.</td>\n",
       "      <td>While the Batman franchise has been much malig...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>15-tt0048696</td>\n",
       "      <td>Tarantula</td>\n",
       "      <td>https://www.imdb.com/title/tt0048696/</td>\n",
       "      <td>Prof. Deemer would have to work a LOT harder n...</td>\n",
       "      <td>I've always wondered if director Jack Arnold c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6-tt0076009</td>\n",
       "      <td>Exorcist II: The Heretic</td>\n",
       "      <td>https://www.imdb.com/title/tt0076009/</td>\n",
       "      <td>Funny Movie</td>\n",
       "      <td>Following up one of the greatest horror films ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>18-tt0076009</td>\n",
       "      <td>Exorcist II: The Heretic</td>\n",
       "      <td>https://www.imdb.com/title/tt0076009/</td>\n",
       "      <td>Funnier than Repossessed</td>\n",
       "      <td>Inside this terrible film is an excellent film...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2-tt0085625</td>\n",
       "      <td>Grunt!</td>\n",
       "      <td>https://www.imdb.com/title/tt0085625/</td>\n",
       "      <td>The Best Motion Picture ever produced</td>\n",
       "      <td>10/10 better than Citizen Kane, Casablanca and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1-tt0085625</td>\n",
       "      <td>Grunt!</td>\n",
       "      <td>https://www.imdb.com/title/tt0085625/</td>\n",
       "      <td>TROLL 2 the movie within the movie.</td>\n",
       "      <td>Yes this is the horrible movie the kids in the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                              name  \\\n",
       "0   12-tt0094074  Superman IV: The Quest for Peace   \n",
       "1    5-tt0094074  Superman IV: The Quest for Peace   \n",
       "2    4-tt0059466   Monsters Crash the Pajama Party   \n",
       "3    2-tt0059466   Monsters Crash the Pajama Party   \n",
       "4   10-tt0112462                    Batman Forever   \n",
       "..           ...                               ...   \n",
       "95  15-tt0048696                         Tarantula   \n",
       "96   6-tt0076009          Exorcist II: The Heretic   \n",
       "97  18-tt0076009          Exorcist II: The Heretic   \n",
       "98   2-tt0085625                            Grunt!   \n",
       "99   1-tt0085625                            Grunt!   \n",
       "\n",
       "                                      url  \\\n",
       "0   https://www.imdb.com/title/tt0094074/   \n",
       "1   https://www.imdb.com/title/tt0094074/   \n",
       "2   https://www.imdb.com/title/tt0059466/   \n",
       "3   https://www.imdb.com/title/tt0059466/   \n",
       "4   https://www.imdb.com/title/tt0112462/   \n",
       "..                                    ...   \n",
       "95  https://www.imdb.com/title/tt0048696/   \n",
       "96  https://www.imdb.com/title/tt0076009/   \n",
       "97  https://www.imdb.com/title/tt0076009/   \n",
       "98  https://www.imdb.com/title/tt0085625/   \n",
       "99  https://www.imdb.com/title/tt0085625/   \n",
       "\n",
       "                                                title  \\\n",
       "0               Even Superman couldn't save this one!   \n",
       "1                              The Paradoxical Son...   \n",
       "2                      Horrible movie, but great DVD!   \n",
       "3   This film manages to be both fun and amazingly...   \n",
       "4                   Better than most people remember.   \n",
       "..                                                ...   \n",
       "95  Prof. Deemer would have to work a LOT harder n...   \n",
       "96                                        Funny Movie   \n",
       "97                           Funnier than Repossessed   \n",
       "98              The Best Motion Picture ever produced   \n",
       "99                TROLL 2 the movie within the movie.   \n",
       "\n",
       "                                               review sentiment  \n",
       "0   There is a new nuclear arms race underway. Sup...  negative  \n",
       "1   Superman IV: The Quest for Peace is a good mov...  negative  \n",
       "2   Very odd and very short color film that tries ...  positive  \n",
       "3   The acting, costumes and dialog for \"Monsters ...  positive  \n",
       "4   While the Batman franchise has been much malig...  positive  \n",
       "..                                                ...       ...  \n",
       "95  I've always wondered if director Jack Arnold c...       NaN  \n",
       "96  Following up one of the greatest horror films ...       NaN  \n",
       "97  Inside this terrible film is an excellent film...       NaN  \n",
       "98  10/10 better than Citizen Kane, Casablanca and...       NaN  \n",
       "99  Yes this is the horrible movie the kids in the...       NaN  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv(os.path.join(data_dir, 'imdb_reviews_annot.csv'), index_col=0)\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa12bba2a9ed8318ce6903b5ebddd45f",
     "grade": false,
     "grade_id": "cell-f90fb872d00876a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\" style=\"color:black\"><h2>1.3 Exercise: Annotate sentiment labels for the reviews</h2>\n",
    "\n",
    "We are going to be analysing the sentiment of these reviews, so we need to add some sentiment labels. Later we can use these as an extra test set to evaluate a classifier. If we had more items to label it would be a good idea to use [Labelbox](https://labelbox.com/) or [Label Studio](https://labelstud.io/). However, as we only have 100 to label we can do this manually.\n",
    "\n",
    "You can either edit the csv file manually or use the following code which will iterate over the reviews and prompt to input either `0` for 'negative', or  `1` for 'positive'.\n",
    "\n",
    "You can stop at any time because the Dataframe is saved after each annotation. You will just need to re-load the data with the cell above and change the name to `imdb_reviews_annot.csv`.\n",
    "\n",
    "<b>Don't over think this!</b> It shouldn't take more than an hour (at most) to label all 100 reviews.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grading:\n",
    "    # Get a list of unlabelled reviews\n",
    "    unlabelled_reviews = [i for i, j in enumerate(list(reviews_df['sentiment'].isnull())) if j]\n",
    "\n",
    "    for i in unlabelled_reviews:\n",
    "        # Display the movie title and review\n",
    "        print(f\"Movie: {reviews_df['name'][i]} ({reviews_df['id'][i]})\")\n",
    "        print(f\"Title: {reviews_df['title'][i]}\")\n",
    "        # Add some newlines to the review for better readability\n",
    "        review = reviews_df['review'][i].replace('.', '.\\n').strip()\n",
    "        print(f\"Review: {review}\\n\")\n",
    "\n",
    "        # Ask for the sentiment label\n",
    "        # Must be Negative (0) or Positive (1)\n",
    "        time.sleep(1)\n",
    "        while True:\n",
    "            label = input(\"Is this review Negative (0) or Positive (1)?\")\n",
    "            if label == '0':\n",
    "                reviews_df.loc[i, 'sentiment'] = 'negative'\n",
    "                break\n",
    "            elif label == '1':\n",
    "                reviews_df.loc[i, 'sentiment'] = 'positive'\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter 0 or 1.\")\n",
    "\n",
    "        # Clear the console and save the dataframe\n",
    "        clear_output()\n",
    "        reviews_df.to_csv(os.path.join(data_dir, 'imdb_reviews_annot.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61b6dadfeed51541bbc6d0b7df962005",
     "grade": false,
     "grade_id": "cell-93831789b3a2d6e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check the number of labelled reviews/progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 56\n",
      "Number of negative reviews: 44\n",
      "Number of unlabelled reviews: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the labelled reviews\n",
    "print(f\"Number of positive reviews: {(reviews_df['sentiment'] == 'positive').sum()}\")\n",
    "print(f\"Number of negative reviews: {(reviews_df['sentiment'] == 'negative').sum()}\")\n",
    "print(f\"Number of unlabelled reviews: {reviews_df['sentiment'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f11c0d0bb057f55de02b5bf0a09e4a0b",
     "grade": false,
     "grade_id": "cell-8b64bc0c8ca11fb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color:black\"><h3>Before you submit this notebook to NBGrader for marking:</h3> \n",
    "\n",
    "1. Make sure have completed all exercises marked by <span style=\"color:blue\">**blue cells**</span>.\n",
    "2. For automatically marked exercises ensure you have completed any cells with `# YOUR CODE HERE`. Then click 'Validate' button above, or ensure all cells run without producing an error.\n",
    "3. For manually marked exercises ensure you have completed any cells with `\"YOUR ANSWER HERE\"`.\n",
    "4. Ensure all cells are run with their output visible.\n",
    "5. Fill in your student ID (**only**) below.\n",
    "6. You should now **save and download** your work.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID:** 15006280"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_ai",
   "language": "python",
   "name": "adv_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
