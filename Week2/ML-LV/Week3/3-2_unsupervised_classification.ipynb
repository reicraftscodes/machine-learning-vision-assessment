{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec3b07ff8b298d278fafb630a27b62ea",
     "grade": false,
     "grade_id": "cell-c579d535b0fd0e0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-danger\" style=\"color:black\"><b>Running ML-LV Jupyter Notebooks:</b><br>\n",
    "    <ol>\n",
    "        <li>Make sure you are running all notebooks using the <code>adv_ai</code> kernel.\n",
    "        <li><b>It is very important that you do not create any additional files within the weekly folders on CSCT cloud.</b> Any additional files, or editing the notebooks with a different environment may prevent submission/marking of your work.</li>\n",
    "            <ul>\n",
    "                <li>NBGrader will automatically fetch and create the correct folders files for you.</li>\n",
    "                <li>All files that are not the Jupyter notebooks should be stored in the 'ML-LV/data' directory.</li>\n",
    "            </ul>\n",
    "        <li>Please <b>do not pip install</b> any python packages (or anything else). You should not need to install anything to complete these notebooks other than the packages provided in the Jupyter CSCT Cloud environment.</li>\n",
    "    </ol>\n",
    "    <b>If you would like to run this notebook locally you should:</b><br>\n",
    "    <ol>\n",
    "        <li>Create an environment using the requirements.txt file provided. <b>Any additional packages you install will not be accessible when uploaded to the server and may prevent marking.</b></li>\n",
    "        <li>Download a copy  of the notebook to your own machine. You can then edit the cells as you wish and then go back and copy the code into/edit the ones on the CSCT cloud in-place.</li>\n",
    "        <li><b>It is very important that you do not re-upload any notebooks that you have edited locally.</b> This is because NBGrader uses cell metadata to track marked tasks. <b>If you change this format it may prevent marking.</b></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fab4c4429368a710b300d4b3778275ba",
     "grade": false,
     "grade_id": "cell-74b51c9c55640619",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2 Unsupervised Text Classification\n",
    "\n",
    "## 2.0 Import libraries\n",
    "\n",
    "1. [Gensim](https://radimrehurek.com/gensim/index.html) - is primarily a Python Topic Modelling library. It also has lots of useful features for working with Word Vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "%matplotlib inline\n",
    "\n",
    "# Get the status of NBgrader (for skipping cell execution while validating/grading)\n",
    "grading = True if os.getenv('NBGRADER_EXECUTION') else False\n",
    "\n",
    "# Set seaborn style for matplotlib plots\n",
    "plt.style.use('seaborn-v0_8-white')\n",
    "\n",
    "# Get the project directory (should be in ML-LV)\n",
    "path = ''\n",
    "while os.path.basename(os.path.abspath(path)) != 'ML-LV':\n",
    "    path = os.path.abspath(os.path.join(path, '..'))\n",
    "\n",
    "# Set the directory to the data folder (should be in ML-LV/data/imdb)\n",
    "data_dir = os.path.join(path, 'data', 'imdb')\n",
    "\n",
    "# Set the directory to the shared dataset folder (should be in shared/datasets/imdb)\n",
    "dataset_dir = os.path.join(path, '..', 'shared', 'datasets', 'imdb')\n",
    "\n",
    "# Set the directory to the shared models folder (should be in shared/models/imdb)\n",
    "model_dir = os.path.join(path, '..', 'shared', 'models', 'imdb')\n",
    "\n",
    "# Load the Spacy language model ('en_core_web_md' should be in shared/models/spacy)\n",
    "nlp = spacy.load(os.path.join(path, '..', 'shared', 'models', 'spacy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a09779cb0da077d2daea9e1f26f4ef9",
     "grade": false,
     "grade_id": "cell-a78eae2e3eb7325b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1 Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb dataset\n",
    "imdb_dataset = pd.read_csv(os.path.join(dataset_dir, 'imdb_dataset.csv'))\n",
    "\n",
    "# Load your imdb reviews\n",
    "imdb_reviews = pd.read_csv(os.path.join(data_dir, 'imdb_reviews.csv'))\n",
    "\n",
    "# Convert the sentiment to a binary value\n",
    "imdb_dataset['sentiment'] = pd.get_dummies(imdb_dataset['sentiment'], drop_first=True)\n",
    "imdb_reviews['sentiment'] = pd.get_dummies(imdb_reviews['sentiment'], drop_first=True)\n",
    "\n",
    "imdb_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95f3f403c55e680ef5abc4853d95dc14",
     "grade": false,
     "grade_id": "cell-21595138cd214aba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Process and vectorise the text\n",
    "\n",
    "Unlike our application of Naive Bayes and ANN, for clustering we need to change our input representations and consider two things:\n",
    "- **Zero values** - in Naive Bayes these simply result in low probability and in an ANN inputs of 0 will not impact weight updates.\n",
    "- **Common words** - these *may* have less impact on the probabilistic and ANN approach, but for clustering, since we are calculating the distance/similarity between examples, lots of common but uninformative words will tend to make examples appear closer/more similar.\n",
    "\n",
    "1. We will use sklearn's `TfidfVectorizer()` to tokenise the text and vectorise each review into a TF-IDF values. This should reduce the magnitude of very common words, which are unlikely to provide sentiment information. We will also remove english stop words and ensure a minimum and maximum word frequency.\n",
    "\n",
    "2. To avoid zeros within the input, and enhance important words, we will also scale the TF-IDF values.\n",
    "\n",
    "3. Next use PCA to select only the most important features. Here we use 2 so that the clusters can be plotted in 2D.\n",
    "\n",
    "2. Finally, split into training and validation sets. Use your IMDB reviews as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the vocab size\n",
    "vocab_size = 2000\n",
    "\n",
    "# Create a TfidfVectorizer, StandardScaler and PCA\n",
    "tfidf_vectoriser = TfidfVectorizer(max_features=vocab_size, stop_words='english', max_df=0.95, min_df=2)\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Vectorise the text\n",
    "X = tfidf_vectoriser.fit_transform(imdb_dataset['review']).toarray()\n",
    "X = scaler.fit_transform(X)\n",
    "X = pca.fit_transform(X)\n",
    "print(f'Shape of X: {X.shape}')\n",
    "print(X[:5, :])\n",
    "\n",
    "# Get the class labels\n",
    "y = imdb_dataset['sentiment'].values\n",
    "print(f'Shape of y: {y.shape}')\n",
    "print(y[:5])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorise the text the test set\n",
    "X_test = tfidf_vectoriser.transform(imdb_reviews['review']).toarray()\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Get the class labels\n",
    "y_test = imdb_reviews['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73e982f36c63c01281f07f175bdd3068",
     "grade": false,
     "grade_id": "cell-12f326299959d551",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2 K-means\n",
    "\n",
    "K-means is a clustering algorithm which defines a set of centroids (mid-points) for each cluster.\n",
    "\n",
    "Examples are assigned to the closest cluster/centroid. Centroids are repeatedly moved to a new mid-point of all examples in the cluster, until no further changes are made.\n",
    "\n",
    "Pseudocode:\n",
    "```\n",
    "Set K number of centroids and randomly assign to examples\n",
    "Set converged = False\n",
    "\n",
    "WHILE not converged:\n",
    "\tFor each example i:\n",
    "\t\tFor each cluster k:\n",
    "\t\t\tCalculate distance(i, k)\n",
    "\t\tAssign i to cluster with smallest distance\n",
    "\t\n",
    "\tIF no examples moved cluster:\n",
    "\t\tconverged = True\n",
    "\tELSE:\n",
    "\t\tFor each cluster k:\n",
    "\t\t\tSET new cluster centroid = average position of examples in cluster\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2136896bf4faac70de1b7d45f9abfecf",
     "grade": false,
     "grade_id": "cell-fb5b963b055a0b2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grading:\n",
    "    # Create and train a Kmeans\n",
    "    kmeans = KMeans(n_clusters=2, n_init=1, init='random', random_state=42)\n",
    "    kmeans.fit(X_train)\n",
    "    \n",
    "    # Predict class labels for validation set\n",
    "    predictions = kmeans.predict(X_val)\n",
    "    print(f'Validation Accuracy: {accuracy_score(y_val, predictions)}')\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    conf_matrix = ConfusionMatrixDisplay.from_predictions(y_val, predictions, display_labels=['negative', 'positive'], colorbar=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "065e7837a0f29d2c9ea70be7e1a72c90",
     "grade": false,
     "grade_id": "cell-1b2d61deea6dcb16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluate the model on your IMDB reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grading:\n",
    "    # Predict class labels for test set\n",
    "    predictions = kmeans.predict(X_test)\n",
    "    print(f'Test Accuracy: {accuracy_score(y_test, predictions)}')\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    conf_matrix = ConfusionMatrixDisplay.from_predictions(y_test, predictions, display_labels=['negative', 'positive'], colorbar=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5873e9a9421dd81229a48b28f2b14612",
     "grade": false,
     "grade_id": "cell-c5334ffba60e04cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Plot the decision boundary, cluster centroids and validation and test datapoints\n",
    "\n",
    "Code for plotting is adapted from [here](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grading:\n",
    "    # Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "    h = 0.01  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    \n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Obtain labels for each point in mesh using trained model.\n",
    "    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(1, figsize=(8, 6))\n",
    "    plt.clf()\n",
    "    plt.imshow(\n",
    "        Z,\n",
    "        interpolation=\"nearest\",\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "    \n",
    "    # Plot the validation and test data only\n",
    "    points = np.concatenate((X_val, X_test))\n",
    "    labels =  np.concatenate((y_val, y_test))\n",
    "    \n",
    "    pos_points = np.array([list(points[i]) for i in range(len(points)) if labels[i] == 1])\n",
    "    neg_points = np.array([list(points[i]) for i in range(len(points)) if labels[i] == 0])\n",
    "    \n",
    "    plt.scatter(pos_points[:, 0], pos_points[:, 1], color=\"green\", s=2)\n",
    "    plt.scatter(neg_points[:, 0], neg_points[:, 1], color=\"red\", s=2)\n",
    "    \n",
    "    # Plot the centroids as a white X\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    plt.scatter(\n",
    "        centroids[:, 0],\n",
    "        centroids[:, 1],\n",
    "        marker=\"x\",\n",
    "        s=169,\n",
    "        linewidths=3,\n",
    "        color=\"w\",\n",
    "        zorder=10,\n",
    "    )\n",
    "    \n",
    "    plt.title(\"K-means clustering on the IMDB sentiment data\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef7495ee646d45c74db4e097dc9f1df0",
     "grade": false,
     "grade_id": "cell-e7dc07fc68ea7737",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.3 Semantic Similarity\n",
    "\n",
    "We can use semantic representation of word embeddings to build a simple classifier using a heuristic approach.\n",
    "\n",
    "1. Start with a list(s) of words that are representative of the categories e.g. ‘good’ and ‘bad’ for sentiment.\n",
    "\n",
    "    - Optionally, find other similar words within the corpus using cosine similarity.\n",
    "\n",
    "2. Score each word in an input example according to its similarity to each word in the category lists.\n",
    "\n",
    "3. Average the word scores to produce semantic scores for each category.\n",
    "\n",
    "4. Make predictions based on the category with the highest semantic score.\n",
    "\n",
    "### Process the text\n",
    "\n",
    "Just tokenise and remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb dataset and tokenise the reviews\n",
    "X = imdb_dataset['review'].apply(lambda x: [token.text for token in nlp.tokenizer(x) if not token.is_stop])\n",
    "y = imdb_dataset['sentiment'].values\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load your imdb reviews and tokenise the reviews\n",
    "X_test = imdb_reviews['review'].apply(lambda x: [token.text for token in nlp.tokenizer(x) if not token.is_stop])\n",
    "y_test = imdb_reviews['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64dd4bbc6fce39aa793826862e2572a9",
     "grade": false,
     "grade_id": "cell-5f716b244d2183d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Create a Word2Vec model\n",
    "\n",
    "We will use gensim to load [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) embeddings and fine tune to our corpus of IMDB reviews.\n",
    "\n",
    "- `vector_size` is the size of the embedding.\n",
    "- `window` is the maximum distance between the current and predicted word within a sentence.\n",
    "- `min_count` all words with total frequency lower than this are ignored.\n",
    "- `sg` is the training algorithm: 1 for skip-gram or 0 for CBOW.\n",
    "- `epochs` is the number of training epochs for the model.\n",
    "\n",
    "<div class=\"alert alert-danger\" style=\"color:black\"><b>Warning:</b><br>\n",
    "Training the Word2Vec model can take a few minutes. To save time, and for consistency in testing, a model has been trained and saved beforehand. The code commented out below shows how the model can be trained and saved.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14acbc41d98a3b58534c407dde6c9561",
     "grade": false,
     "grade_id": "cell-631c4b0d5283d13f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a word2vec model with gensim\n",
    "embedding_dim = 300\n",
    "\n",
    "# Train the word2vec model\n",
    "# w2v_model = Word2Vec(sentences=X_train, vector_size=embedding_dim, window=5, min_count=2, sg=1, epochs=3, seed=42, workers=4)\n",
    "# w2v_model.save(os.path.join('imdb_w2v.model'))\n",
    "\n",
    "# Load the word2vec model (to save time)\n",
    "w2v_model = Word2Vec.load(os.path.join(model_dir, 'imdb_w2v.model'))\n",
    "\n",
    "print(f\"Word2Vec vocabulary: {list(w2v_model.wv.key_to_index)[:20]}\")\n",
    "print(f\"Vocabulary size: {len(list(w2v_model.wv.key_to_index))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9908173dec745c6553d88acc050a5bb3",
     "grade": false,
     "grade_id": "cell-946bcea167bc35e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Create a list of positive and negative sentiment words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a selection of positive and negative words\n",
    "pos_words = ['excellent', 'awesome', 'cool', 'decent', 'amazing', 'strong', 'good', 'great', 'funny', 'entertaining']\n",
    "neg_words = ['terrible', 'awful', 'horrible', 'boring', 'bad', 'disappointing', 'weak', 'poor', 'senseless', 'confusing']\n",
    "\n",
    "# Get the most similar words for each word in the positive and negative lists\n",
    "pos_sims = w2v_model.wv.most_similar(pos_words, topn=10)\n",
    "print(f'Positive similar words: {pos_sims}')\n",
    "\n",
    "neg_sims = w2v_model.wv.most_similar(neg_words, topn=10)\n",
    "print(f'Negative similar words: {neg_sims}')\n",
    "\n",
    "# Get the vectors for each word in the positive and negative lists\n",
    "pos_words.extend([word for word, score in pos_sims])\n",
    "pos_vectors = np.array([w2v_model.wv.get_vector(word) for word in pos_words])\n",
    "\n",
    "neg_words.extend([word for word, score in neg_sims])\n",
    "neg_vectors = np.array([w2v_model.wv.get_vector(word) for word in neg_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3889b64631f63db44b81442edd5081cc",
     "grade": false,
     "grade_id": "cell-5f8d72e15a7866f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Calculate the semantic score of each review<\n",
    "\n",
    "Now that we have a Word2Vec model trained on the IMDB data and a list of positive and negative words, we can create a simple semantic similarity classifier.\n",
    "\n",
    "1. The following cell implements the `semantic_similarity()` function. It takes in the following arguments and return a list of predictions and scores:\n",
    "    - `data` is a list of tokenised reviews to be classified.\n",
    "    - `model` is the trained Word2Vec model created above.\n",
    "    - `pos_vectors` is the list of word vectors for the *positive* words created above.\n",
    "    - `neg_vectors` is the list of word vectors for the *negative* words created above.\n",
    "\n",
    "2. The function loops through each review and:\n",
    "    - Converts the tokens to vectors using `model.wv.key_to_index` to check if the word is in the models vocabulary.\n",
    "    - Calculates the positive and negative score for the review by the similarity to the positive and negative vectors.\n",
    "    - Assign a class label: 1 if the average positive scores are > the average negative score, and 0 otherwise.\n",
    "\n",
    "3. Finally returns the predictions for each review and an array of score (positive and negative), for each review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity(data, model, pos_vectors, neg_vectors):\n",
    "    \"\"\"Calculate the semantic similarity for each document.\n",
    "    Arguments:\n",
    "        data (list): A list of tokenised documents\n",
    "        model (Word2Vec): A trained Word2Vec model\n",
    "        pos_vectors (list): A list of positive word vectors\n",
    "        neg_vectors (list): A list of negative word vectors\n",
    "    \"\"\"\n",
    "    # Create an array to store the semantic similarity predictions\n",
    "    predictions = np.zeros((len(data), 1))\n",
    "\n",
    "    # Create an array to store the positive and negative scores\n",
    "    scores = np.zeros((len(data), 2))\n",
    "\n",
    "    # Loop through each document\n",
    "    for i, review in enumerate(data):\n",
    "\n",
    "        # Get the word vectors for the review\n",
    "        review_vec = [model.wv.get_vector(word) for word in review if word in model.wv.key_to_index]\n",
    "\n",
    "        # Calculate the cosine similarity between the positive and negative words and the review\n",
    "        pos_scores = cosine_similarity(review_vec, pos_vectors)\n",
    "        neg_scores = cosine_similarity(review_vec, neg_vectors)\n",
    "\n",
    "        # Add to the average scores to the array\n",
    "        scores[i, 0] = np.mean(pos_scores)\n",
    "        scores[i, 1] = np.mean(neg_scores)\n",
    "\n",
    "    # Make a prediction based on the average scores\n",
    "    predictions = np.argmax(-scores, axis=1)\n",
    "\n",
    "    return predictions, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dce63c48cd028432af5a4cddf2d35aea",
     "grade": false,
     "grade_id": "cell-62013ef43887ef75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Predict sentiment labels according to category with the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grading:\n",
    "    # Predict class labels for validation set\n",
    "    predictions, scores = semantic_similarity(X_val, w2v_model, pos_vectors, neg_vectors)\n",
    "    print(f'Validation Accuracy: {accuracy_score(y_val, predictions)}')\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    conf_matrix = ConfusionMatrixDisplay.from_predictions(y_val, predictions, display_labels=['negative', 'positive'], colorbar=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c337983aa66a13f43eb3f973ab600752",
     "grade": false,
     "grade_id": "cell-323e57b38d66a7c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluate the model on your IMDB reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grading:\n",
    "    # Predict class labels for test set\n",
    "    predictions, scores = semantic_similarity(X_test, w2v_model, pos_vectors, neg_vectors)\n",
    "    print(f'Test Accuracy: {accuracy_score(y_test, predictions)}')\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    conf_matrix = ConfusionMatrixDisplay.from_predictions(y_test, predictions, display_labels=['negative', 'positive'], colorbar=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a57e9b6fa4e42ee103e95c67aa0cc34",
     "grade": false,
     "grade_id": "cell-e22e8692055021b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color:black\"><h3>Before you submit this notebook to NBGrader for marking:</h3> \n",
    "\n",
    "1. Make sure have completed all exercises marked by <span style=\"color:blue\">**blue cells**</span>.\n",
    "2. For automatically marked exercises ensure you have completed any cells with `# YOUR CODE HERE`. Then click 'Validate' button above, or ensure all cells run without producing an error.\n",
    "3. For manually marked exercises ensure you have completed any cells with `\"YOUR ANSWER HERE\"`.\n",
    "4. Ensure all cells are run with their output visible.\n",
    "5. Fill in your student ID (**only**) below.\n",
    "6. You should now **save and download** your work.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
