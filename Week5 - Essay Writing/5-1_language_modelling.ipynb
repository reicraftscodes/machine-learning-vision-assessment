{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7c1cc362bc61db855730c764342af35",
     "grade": false,
     "grade_id": "cell-f7b2189a085f789c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-danger\" style=\"color:black\"><b>Running ML-LV Jupyter Notebooks:</b><br>\n",
    "    <ol>\n",
    "        <li>Make sure you are running all notebooks using the <code>adv_ai</code> kernel.\n",
    "        <li><b>It is very important that you do not create any additional files within the weekly folders on CSCT cloud.</b> Any additional files, or editing the notebooks with a different environment may prevent submission/marking of your work.</li>\n",
    "            <ul>\n",
    "                <li>NBGrader will automatically fetch and create the correct folders files for you.</li>\n",
    "                <li>All files that are not the Jupyter notebooks should be stored in the 'ML-LV/data' directory.</li>\n",
    "            </ul>\n",
    "        <li>Please <b>do not pip install</b> any python packages (or anything else). You should not need to install anything to complete these notebooks other than the packages provided in the Jupyter CSCT Cloud environment.</li>\n",
    "    </ol>\n",
    "    <b>If you would like to run this notebook locally you should:</b><br>\n",
    "    <ol>\n",
    "        <li>Create an environment using the requirements.txt file provided. <b>Any additional packages you install will not be accessible when uploaded to the server and may prevent marking.</b></li>\n",
    "        <li>Download a copy  of the notebook to your own machine. You can then edit the cells as you wish and then go back and copy the code into/edit the ones on the CSCT cloud in-place.</li>\n",
    "        <li><b>It is very important that you do not re-upload any notebooks that you have edited locally.</b> This is because NBGrader uses cell metadata to track marked tasks. <b>If you change this format it may prevent marking.</b></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25e9bbc1999ebab2387fce86d3f94ee0",
     "grade": false,
     "grade_id": "cell-0254e24de97e6b8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Practical 5: Language Modelling\n",
    "\n",
    "Language models attempt to create a generalised long-term model of language. That is, a model that has learned the characteristics of the language it was trained on, such as grammar, punctuation, the relationship between words and so on. Typically, language models predict the next token of a sequence, given the previous tokens, or simply calculate the probability of a sequence of tokens. This can be implemented with a simple n-gram language model, but these are limited to predicting only sequences of n-grams (word combinations) observed within the training data.\n",
    "\n",
    "In contrast, ML language models are much more robust and capable of generating more varied and 'imaginative' texts. RNN are well suited to this task due to their sequential processing of input. However, modern stat-of-the-art language models, such as [GPT-4](https://openai.com/gpt-4), use [Transformers](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)). In either case LM are typically trained on very large natural language datasets, such as Wikipedia, Amazon reviews, Google books, or in our case Sherlock Holmes stories! Importantly, and similar to word vectors, once trained, the model of language that has been learned can be transferred to other downstream tasks, such as classification and translation.\n",
    "\n",
    "In the first part of this practical we will create two n-gram language models. The first will simply calculate the probability of an input sentence, given the training corpus. The second will generate the next word, given the previous words in a sequence.\n",
    "\n",
    "In the second part of this practical we will create an RNN language model using the complete works of [Sherlock Holmes by Sir Aurthur Conan Doyle](https://sherlock-holm.es/) as a training corpus. Then we will use the trained model to generate sentences in the style of Conan Doyle, and explore various different methods of sampling from the word probabilities generated by the model.\n",
    "\n",
    "The objectives of this practical are:\n",
    "1. Understand the key concepts of language modelling and evaluation: calculating the probability of a sentence or next token and calculating perplexity\n",
    "\n",
    "2. Introduce new ML techniques that are useful for building large models: data generators, custom metrics, early stopping and checkpointing\n",
    "\n",
    "3. Compare and contrast different sampling methods, such as greedy, temperature and top-k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c08c5cb60fef38972b4fc746da0129ea",
     "grade": false,
     "grade_id": "cell-e2cd28714f191858",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1 N-gram Language Models\n",
    "\n",
    "## 1.0 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b2229aa912d61743995cd119e5d52b7",
     "grade": false,
     "grade_id": "cell-5926bf3a45a46723",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Probability of a sentence\n",
    "\n",
    "We can create simple language models using n-grams. Whether we are calculating the probability of a sequence, or trying to predict the next word, the first step is the same: calculate the probability of a word given the previous word (bi-gram), or words (tri-gram +).\n",
    "\n",
    "So, for each n-gram within the training corpus we need to calculate:\n",
    "\n",
    "$P(word|previous \\; words) = \\frac{count(previous \\; words, \\; word)}{count(previous \\; words)}$\n",
    "\n",
    "The language model is then effectively the set of n-gram probabilites that have been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams: Counter({('this', 'is'): 3, ('is', 'a'): 2, ('i', 'love'): 2, ('love', 'my'): 2, ('a', 'dog'): 1, ('a', 'cat'): 1, ('my', 'cat'): 1, ('my', 'dog'): 1, ('is', 'my'): 1, ('my', 'name'): 1})\n",
      "Uni-grams: Counter({'this': 3, 'is': 3, 'my': 3, 'a': 2, 'dog': 2, 'cat': 2, 'i': 2, 'love': 2, 'name': 1})\n",
      "P(('is',)|this) = 1.0000\n",
      "P(('a',)|is) = 0.6667\n",
      "P(('dog',)|a) = 0.5000\n",
      "P(('is',)|this) = 1.0000\n",
      "P(('a',)|is) = 0.6667\n",
      "P(('cat',)|a) = 0.5000\n",
      "P(('love',)|i) = 1.0000\n",
      "P(('my',)|love) = 1.0000\n",
      "P(('cat',)|my) = 0.3333\n",
      "P(('love',)|i) = 1.0000\n",
      "P(('my',)|love) = 1.0000\n",
      "P(('dog',)|my) = 0.3333\n",
      "P(('is',)|this) = 1.0000\n",
      "P(('my',)|is) = 0.3333\n",
      "P(('name',)|my) = 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Define the corpus\n",
    "corpus = ['This is a dog', 'This is a cat', 'I love my cat', 'I love my dog', 'This is my name']\n",
    "\n",
    "# Count the unigrams and n-grams\n",
    "N = 2\n",
    "n_grams = []\n",
    "uni_grams = []\n",
    "for sent in corpus:\n",
    "    tokens = sent.lower().split()\n",
    "    n_grams.extend(list(ngrams(tokens, N)))\n",
    "    uni_grams.extend(tokens)\n",
    "\n",
    "n_gram_count = Counter(n_grams)\n",
    "print(f\"{N}-grams: {n_gram_count}\")\n",
    "uni_gram_count = Counter(uni_grams)\n",
    "print(f\"Uni-grams: {uni_gram_count}\")\n",
    "\n",
    "# Calculate the n-gram probabilities\n",
    "n_gram_probs = {}\n",
    "for n_gram in n_grams:\n",
    "    n_gram_probs[n_gram] = n_gram_count[n_gram] / uni_gram_count[n_gram[0]]\n",
    "    print(f\"P({n_gram[1:]}|{n_gram[0]}) = {n_gram_probs[n_gram]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "245af8a6722b4d0108120beaf9115f94",
     "grade": false,
     "grade_id": "cell-1c9c6bd521bac77a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once we have calculated the n-gram probabilities, calculating the probability of a sentence is simply:\n",
    "\n",
    "1. Count the n-grams in the input sentence\n",
    "\n",
    "2. Find the product of all n-grams that exist within both the model and the input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams: [('this', 'is'), ('is', 'my'), ('my', 'dog')]\n",
      "2-gram: ('this', 'is') probability: 1.0\n",
      "2-gram: ('is', 'my') probability: 0.333\n",
      "2-gram: ('my', 'dog') probability: 0.333\n",
      "Probablility of sentence \"This is my dog\" = 0.1111\n"
     ]
    }
   ],
   "source": [
    "# Sentence to calculate probability of\n",
    "sentence = \"This is my dog\"\n",
    "\n",
    "# Count n-grams\n",
    "sentence_n_grams = list(ngrams([token.lower() for token in sentence.split()], N))\n",
    "print(f\"{N}-grams: {sentence_n_grams}\")\n",
    "\n",
    "# Calculate probability of sentence\n",
    "probability = 1\n",
    "# For each n-gram in sentence\n",
    "for n_gram in sentence_n_grams:\n",
    "\n",
    "    # If its probability is in the training corpus\n",
    "    if n_gram in n_gram_probs:\n",
    "        print(f\"{N}-gram: {n_gram} probability: {round(n_gram_probs[n_gram], 3)}\")\n",
    "\n",
    "        # Multiply the probability of the n-gram to the total probability\n",
    "        probability *= n_gram_probs[n_gram]\n",
    "\n",
    "print(f\"Probablility of sentence \\\"{sentence}\\\" = {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7533cca3088dd77a43c6d784ec4871a8",
     "grade": false,
     "grade_id": "cell-6d0ab4b27b422a8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 Probability of next word\n",
    "\n",
    "To calculate the probability of the next word in a sequence we need to build a language model in the same manner as before, by finding the probability of a word given the previous word(s):\n",
    "\n",
    "$P(word|previous \\; words) = \\frac{count(previous \\; words, \\; word)}{count(previous \\; words)}$\n",
    "\n",
    "Note that here we have added two special tokens, `<s>` signifies the start of a sentence and `</s>` the end. This is often useful when generating text because it provides a generic starting, and potentially end point, for the generation process. Otherwise you would always need to provide a starting token/word, such as 'I', and this would influence selection of the following tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams: Counter({('<s>', 'i'): 2, ('i', 'am'): 2, ('am', 'sam'): 1, ('sam', '</s>'): 1, ('<s>', 'sam'): 1, ('sam', 'i'): 1, ('am', '</s>'): 1, ('i', 'do'): 1, ('do', 'not'): 1, ('not', 'like'): 1, ('like', 'green'): 1, ('green', 'eggs'): 1, ('eggs', 'and'): 1, ('and', 'ham'): 1, ('ham', '</s>'): 1})\n",
      "Uni-grams: Counter({'<s>': 3, 'i': 3, '</s>': 3, 'am': 2, 'sam': 2, 'do': 1, 'not': 1, 'like': 1, 'green': 1, 'eggs': 1, 'and': 1, 'ham': 1})\n",
      "P(('i',)|<s>) = 0.6667\n",
      "P(('am',)|i) = 0.6667\n",
      "P(('sam',)|am) = 0.5000\n",
      "P(('</s>',)|sam) = 0.5000\n",
      "P(('sam',)|<s>) = 0.3333\n",
      "P(('i',)|sam) = 0.5000\n",
      "P(('am',)|i) = 0.6667\n",
      "P(('</s>',)|am) = 0.5000\n",
      "P(('i',)|<s>) = 0.6667\n",
      "P(('do',)|i) = 0.3333\n",
      "P(('not',)|do) = 1.0000\n",
      "P(('like',)|not) = 1.0000\n",
      "P(('green',)|like) = 1.0000\n",
      "P(('eggs',)|green) = 1.0000\n",
      "P(('and',)|eggs) = 1.0000\n",
      "P(('ham',)|and) = 1.0000\n",
      "P(('</s>',)|ham) = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define the corpus\n",
    "corpus = ['<s> I am Sam </s>', '<s> Sam I am </s>', '<s> I do not like green eggs and ham </s>']\n",
    "\n",
    "# Calculate the unigram and n-gram counts\n",
    "N = 2\n",
    "n_grams = []\n",
    "uni_grams = []\n",
    "for sent in corpus:\n",
    "    tokens = sent.lower().split()\n",
    "    n_grams.extend(list(ngrams(tokens, N)))\n",
    "    uni_grams.extend(tokens)\n",
    "\n",
    "n_gram_count = Counter(n_grams)\n",
    "print(f\"{N}-grams: {n_gram_count}\")\n",
    "uni_gram_count = Counter(uni_grams)\n",
    "print(f\"Uni-grams: {uni_gram_count}\")\n",
    "\n",
    "# Calculate the n-gram probabilities\n",
    "n_gram_probs = {}\n",
    "for n_gram in n_grams:\n",
    "    n_gram_probs[n_gram] = n_gram_count[n_gram] / uni_gram_count[n_gram[0]]\n",
    "    print(f\"P({n_gram[1:]}|{n_gram[0]}) = {n_gram_probs[n_gram]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9bbe7d12b48c377e6dc896cadf3fd046",
     "grade": false,
     "grade_id": "cell-431b279499ac35fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once we have created the model, by calculating the n-gram probabilities, we can use it to generate text:\n",
    "\n",
    "1. First start with the seed tokens/text which will 'prompt' the model for the next token. In this case we can simply use the start of a sentence token (`<s>`).\n",
    "\n",
    "2. Loop until the end of sentence token (`</s>`) is generated, or a maximum sequence length is reached. At each step:\n",
    "\n",
    "    1. Find *all* the possible next tokens given the previous token.\n",
    "\n",
    "    2. Select the next token using the greedy sampling method.\n",
    "\n",
    "    3. Add the selected token to the generated text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible tokens: ['i: 0.6667', 'sam: 0.3333']\n",
      "Next token: i\n",
      "\n",
      "Possible tokens: ['am: 0.6667', 'do: 0.3333']\n",
      "Next token: am\n",
      "\n",
      "Possible tokens: ['sam: 0.5000', '</s>: 0.5000']\n",
      "Next token: sam\n",
      "\n",
      "Possible tokens: ['</s>: 0.5000', 'i: 0.5000']\n",
      "Next token: </s>\n",
      "\n",
      "Generated text: <s> i am sam </s>\n"
     ]
    }
   ],
   "source": [
    "# Set the seed text\n",
    "generated_text = \"<s>\"\n",
    "# Variable to hold the next token\n",
    "next_token = ''\n",
    "# Set the maximum sequence length\n",
    "max_seq_len = 10\n",
    "\n",
    "# While next token is not end of sentence and max sequence length is not reached\n",
    "i = 0\n",
    "while next_token != '</s>' and len(generated_text.split()) < max_seq_len:\n",
    "\n",
    "    # Tokenize generated text\n",
    "    tokens = generated_text.lower().split()\n",
    "\n",
    "    possible_next_tokens = {}\n",
    "    # Find possible next tokens\n",
    "    for n_gram, prob in n_gram_probs.items():\n",
    "        # If last token of generated text is the first token of n-gram\n",
    "        if n_gram[0] == tokens[-1]:\n",
    "            # Add n-gram to possible next tokens\n",
    "            possible_next_tokens[n_gram[1]] = prob\n",
    "\n",
    "    print(f'Possible tokens: {[f\"{k}: {v:.4f}\" for k, v in possible_next_tokens.items()]}')\n",
    "\n",
    "    # Greedily select next token\n",
    "\n",
    "    # Find highest probability\n",
    "    highest_prob = list(sorted(possible_next_tokens.items(), key=lambda item: item[1]))[-1][1]\n",
    "\n",
    "    # Remove all tokens with lower probability (in case of ties)\n",
    "    possible_next_tokens = {token: prob for token, prob in possible_next_tokens.items() if prob == highest_prob}\n",
    "    \n",
    "    # Randomly select next token\n",
    "    next_token = np.random.choice(list(possible_next_tokens.keys()))\n",
    "\n",
    "    print(f'Next token: {next_token}\\n')\n",
    "\n",
    "    # Add next token to generated text\n",
    "    generated_text += ' ' + next_token\n",
    "    i += 1\n",
    "\n",
    "print(f'Generated text: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "002697eadaf0efb2a1b330f981ecae46",
     "grade": false,
     "grade_id": "cell-44f5294b234a9f85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\" style=\"color:black\"><h2>1.3 Exercise: Different sampling methods</h2>\n",
    "\n",
    "The above algorithm uses a 'greedy' sampling method, which simply selects the most probable token from all possible next tokens. However, even with large sophisticated language models greedy sampling often results in generic and repetitive text.\n",
    "\n",
    "1. In the following cell complete the `generate_text()` function by adding a few other sampling methods.  It should take the following arguments and return a string of generated text:\n",
    "    - `model` is an n-gram language model consisting of a dictionary of words (keys) and probabilities (values).\n",
    "    - `seed_text` is the seed text to start generation with. Typically the `<s>` token.\n",
    "    - `max_seq_len` is the maximum possible length of a generated sequence.\n",
    "    - `sampling_method` is the sampling method to use. One of 'greedy', 'eager', 'random' or 'weighted_random'.\n",
    "    - `verbose` is whether to print the generated tokens at each generation step.\n",
    "\n",
    "2. Add the following sampling methods:\n",
    "\n",
    "    - 'eager', which selects the first possible token\n",
    "\n",
    "    - 'random', which randomly selects from all possible tokens\n",
    "    \n",
    "    - 'weighted_random', which randomly selects from all possible tokens weighted by the token probability. This can be simply implemented using `np.random.choice()`\n",
    "\n",
    "3. You can test the function using the Green Eggs and Ham or I Wandered Lonely as a Cloud poem by William Wordsworth (below).\n",
    "\n",
    "<br>\n",
    "<b>This exercise is <u>not</u> marked.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "378f37e1193f2b6343f8ba41e0b1f527",
     "grade": false,
     "grade_id": "cell-f5704374a113da8c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, seed_text='<s>', max_seq_len=10, sampling_method='greedy', verbose=True):\n",
    "    \"\"\"Generates text by sampling from an n-gram language model.\n",
    "    \n",
    "    Arguments:\n",
    "        model (dict): An n-gram language model as a dictionary of n-grams and their probabilities\n",
    "        seed_text (str): The seed text to start the generation with\n",
    "        max_seq_len (int): The maximum length of the generated sequence\n",
    "        sampling_method (str): The sampling method to use. One of 'greedy', 'eager', 'random' or 'weighted_random'\n",
    "        verbose (bool): Whether to print the generated tokens at each generation step\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the seed text\n",
    "    generated_text = seed_text\n",
    "    # Variable to hold the next token\n",
    "    next_token = ''\n",
    "\n",
    "    # While next token is not end of sentence and max sequence length is not reached\n",
    "    i = 0\n",
    "    while next_token != '</s>' and len(generated_text.split()) < max_seq_len:\n",
    "\n",
    "        # Tokenize generated text\n",
    "        tokens = generated_text.lower().split()\n",
    "\n",
    "        possible_next_tokens = {}\n",
    "        # Find possible next tokens\n",
    "        for n_gram, prob in model.items():\n",
    "            # If last token of generated text is the first token of n-gram\n",
    "            if n_gram[0] == tokens[-1]:\n",
    "                # Add n-gram to possible next tokens\n",
    "                possible_next_tokens[n_gram[1]] = prob\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Possible tokens: {[f\"{k}: {v:.4f}\" for k, v in possible_next_tokens.items()]}')\n",
    "\n",
    "        # Select next token\n",
    "        # Greedy choice (highest probability)\n",
    "        if sampling_method == 'greedy':\n",
    "            # Find highest probability\n",
    "            highest_prob = list(sorted(possible_next_tokens.items(), key=lambda item: item[1]))[-1][1]\n",
    "            # Remove all tokens with lower probability (in case of ties)\n",
    "            possible_next_tokens = {token: prob for token, prob in possible_next_tokens.items() if prob == highest_prob}\n",
    "            # Randomly select next token\n",
    "            next_token = np.random.choice(list(possible_next_tokens.keys()))\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # raise NotImplementedError()\n",
    "        # first token found\n",
    "        elif sampling_method == 'eager':\n",
    "            if possible_next_tokens:\n",
    "                # Take the first token from the dictionary\n",
    "                next_token = list(possible_next_tokens.keys())[0]\n",
    "            else:\n",
    "                # If no possible next tokens, end generation\n",
    "                next_token = '</s>'\n",
    "\n",
    "        # Random choice (uniform random selection)\n",
    "        elif sampling_method == 'random':\n",
    "            if possible_next_tokens:\n",
    "                # Randomly select a token with equal probability\n",
    "                next_token = np.random.choice(list(possible_next_tokens.keys()))\n",
    "            else:\n",
    "                # If no possible next tokens, end generation\n",
    "                next_token = '</s>'\n",
    "\n",
    "        # Weighted random choice (probability-weighted selection)\n",
    "        elif sampling_method == 'weighted_random':\n",
    "            if possible_next_tokens:\n",
    "                tokens = list(possible_next_tokens.keys())\n",
    "                probs = list(possible_next_tokens.values())\n",
    "                # Normalize probabilities to sum to 1\n",
    "                probs = np.array(probs) / sum(probs)\n",
    "                # Select token weighted by probabilities\n",
    "                next_token = np.random.choice(tokens, p=probs)\n",
    "            else:\n",
    "                # If no possible next tokens, end generation\n",
    "                next_token = '</s>'\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown sampling method: {sampling_method}\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Next token: {next_token}\\n')\n",
    "\n",
    "        # Add next token to generated text\n",
    "        generated_text += ' ' + next_token\n",
    "        i += 1\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams: Counter({('<s>', 'and'): 3, ('<s>', 'i'): 2, ('<s>', 'a'): 2, ('daffodils', '</s>'): 2, ('<s>', 'they'): 2, ('<s>', 'in'): 2, ('i', 'wandered'): 1, ('wandered', 'lonely'): 1, ('lonely', 'as'): 1, ('as', 'a'): 1, ('a', 'cloud'): 1, ('cloud', '</s>'): 1, ('<s>', 'that'): 1, ('that', 'floats'): 1, ('floats', 'on'): 1, ('on', 'high'): 1, ('high', 'o'): 1, ('o', 'er'): 1, ('er', 'vales'): 1, ('vales', 'and'): 1, ('and', 'hills'): 1, ('hills', '</s>'): 1, ('<s>', 'when'): 1, ('when', 'all'): 1, ('all', 'at'): 1, ('at', 'once'): 1, ('once', 'i'): 1, ('i', 'saw'): 1, ('saw', 'a'): 1, ('a', 'crowd'): 1, ('crowd', '</s>'): 1, ('a', 'host'): 1, ('host', 'of'): 1, ('of', 'golden'): 1, ('golden', 'daffodils'): 1, ('<s>', 'beside'): 1, ('beside', 'the'): 1, ('the', 'lake'): 1, ('lake', 'beneath'): 1, ('beneath', 'the'): 1, ('the', 'trees'): 1, ('trees', '</s>'): 1, ('<s>', 'fluttering'): 1, ('fluttering', 'and'): 1, ('and', 'dancing'): 1, ('dancing', 'in'): 1, ('in', 'the'): 1, ('the', 'breeze'): 1, ('breeze', '</s>'): 1, ('<s>', 'continuous'): 1, ('continuous', 'as'): 1, ('as', 'the'): 1, ('the', 'stars'): 1, ('stars', 'that'): 1, ('that', 'shine'): 1, ('shine', '</s>'): 1, ('and', 'twinkle'): 1, ('twinkle', 'on'): 1, ('on', 'the'): 1, ('the', 'milky'): 1, ('milky', 'way'): 1, ('way', '</s>'): 1, ('they', 'stretched'): 1, ('stretched', 'in'): 1, ('in', 'never'): 1, ('never', 'ending'): 1, ('ending', 'line'): 1, ('line', '</s>'): 1, ('<s>', 'along'): 1, ('along', 'the'): 1, ('the', 'margin'): 1, ('margin', 'of'): 1, ('of', 'a'): 1, ('a', 'bay'): 1, ('bay', '</s>'): 1, ('<s>', 'ten'): 1, ('ten', 'thousand'): 1, ('thousand', 'saw'): 1, ('saw', 'i'): 1, ('i', 'at'): 1, ('at', 'a'): 1, ('a', 'glance'): 1, ('glance', '</s>'): 1, ('<s>', 'tossing'): 1, ('tossing', 'their'): 1, ('their', 'heads'): 1, ('heads', 'in'): 1, ('in', 'sprightly'): 1, ('sprightly', 'dance'): 1, ('dance', '</s>'): 1, ('<s>', 'the'): 1, ('the', 'waves'): 1, ('waves', 'beside'): 1, ('beside', 'them'): 1, ('them', 'danced'): 1, ('danced', 'but'): 1, ('but', 'they'): 1, ('they', '</s>'): 1, ('<s>', 'out'): 1, ('out', 'did'): 1, ('did', 'the'): 1, ('the', 'sparkling'): 1, ('sparkling', 'waves'): 1, ('waves', 'in'): 1, ('in', 'glee'): 1, ('glee', '</s>'): 1, ('a', 'poet'): 1, ('poet', 'could'): 1, ('could', 'not'): 1, ('not', 'but'): 1, ('but', 'be'): 1, ('be', 'gay'): 1, ('gay', '</s>'): 1, ('in', 'such'): 1, ('such', 'a'): 1, ('a', 'jocund'): 1, ('jocund', 'company'): 1, ('company', '</s>'): 1, ('i', 'gazed'): 1, ('gazed', 'and'): 1, ('and', 'gazed'): 1, ('gazed', 'but'): 1, ('but', 'little'): 1, ('little', 'thought'): 1, ('thought', '</s>'): 1, ('<s>', 'what'): 1, ('what', 'wealth'): 1, ('wealth', 'the'): 1, ('the', 'show'): 1, ('show', 'to'): 1, ('to', 'me'): 1, ('me', 'had'): 1, ('had', 'brought'): 1, ('brought', '</s>'): 1, ('<s>', 'for'): 1, ('for', 'oft'): 1, ('oft', 'when'): 1, ('when', 'on'): 1, ('on', 'my'): 1, ('my', 'couch'): 1, ('couch', 'i'): 1, ('i', 'lie'): 1, ('lie', '</s>'): 1, ('in', 'vacant'): 1, ('vacant', 'or'): 1, ('or', 'in'): 1, ('in', 'pensive'): 1, ('pensive', 'mood'): 1, ('mood', '</s>'): 1, ('they', 'flash'): 1, ('flash', 'upon'): 1, ('upon', 'that'): 1, ('that', 'inward'): 1, ('inward', 'eye'): 1, ('eye', '</s>'): 1, ('<s>', 'which'): 1, ('which', 'is'): 1, ('is', 'the'): 1, ('the', 'bliss'): 1, ('bliss', 'of'): 1, ('of', 'solitude'): 1, ('solitude', '</s>'): 1, ('and', 'then'): 1, ('then', 'my'): 1, ('my', 'heart'): 1, ('heart', 'with'): 1, ('with', 'pleasure'): 1, ('pleasure', 'fills'): 1, ('fills', '</s>'): 1, ('and', 'dances'): 1, ('dances', 'with'): 1, ('with', 'the'): 1, ('the', 'daffodils'): 1})\n",
      "Uni-grams: Counter({'<s>': 24, '</s>': 24, 'the': 11, 'a': 7, 'in': 7, 'and': 6, 'i': 5, 'that': 3, 'on': 3, 'of': 3, 'they': 3, 'but': 3, 'as': 2, 'when': 2, 'at': 2, 'saw': 2, 'daffodils': 2, 'beside': 2, 'waves': 2, 'gazed': 2, 'my': 2, 'with': 2, 'wandered': 1, 'lonely': 1, 'cloud': 1, 'floats': 1, 'high': 1, 'o': 1, 'er': 1, 'vales': 1, 'hills': 1, 'all': 1, 'once': 1, 'crowd': 1, 'host': 1, 'golden': 1, 'lake': 1, 'beneath': 1, 'trees': 1, 'fluttering': 1, 'dancing': 1, 'breeze': 1, 'continuous': 1, 'stars': 1, 'shine': 1, 'twinkle': 1, 'milky': 1, 'way': 1, 'stretched': 1, 'never': 1, 'ending': 1, 'line': 1, 'along': 1, 'margin': 1, 'bay': 1, 'ten': 1, 'thousand': 1, 'glance': 1, 'tossing': 1, 'their': 1, 'heads': 1, 'sprightly': 1, 'dance': 1, 'them': 1, 'danced': 1, 'out': 1, 'did': 1, 'sparkling': 1, 'glee': 1, 'poet': 1, 'could': 1, 'not': 1, 'be': 1, 'gay': 1, 'such': 1, 'jocund': 1, 'company': 1, 'little': 1, 'thought': 1, 'what': 1, 'wealth': 1, 'show': 1, 'to': 1, 'me': 1, 'had': 1, 'brought': 1, 'for': 1, 'oft': 1, 'couch': 1, 'lie': 1, 'vacant': 1, 'or': 1, 'pensive': 1, 'mood': 1, 'flash': 1, 'upon': 1, 'inward': 1, 'eye': 1, 'which': 1, 'is': 1, 'bliss': 1, 'solitude': 1, 'then': 1, 'heart': 1, 'pleasure': 1, 'fills': 1, 'dances': 1})\n",
      "P(('i',)|<s>) = 0.0833\n",
      "P(('wandered',)|i) = 0.2000\n",
      "P(('lonely',)|wandered) = 1.0000\n",
      "P(('as',)|lonely) = 1.0000\n",
      "P(('a',)|as) = 0.5000\n",
      "P(('cloud',)|a) = 0.1429\n",
      "P(('</s>',)|cloud) = 1.0000\n",
      "P(('that',)|<s>) = 0.0417\n",
      "P(('floats',)|that) = 0.3333\n",
      "P(('on',)|floats) = 1.0000\n",
      "P(('high',)|on) = 0.3333\n",
      "P(('o',)|high) = 1.0000\n",
      "P(('er',)|o) = 1.0000\n",
      "P(('vales',)|er) = 1.0000\n",
      "P(('and',)|vales) = 1.0000\n",
      "P(('hills',)|and) = 0.1667\n",
      "P(('</s>',)|hills) = 1.0000\n",
      "P(('when',)|<s>) = 0.0417\n",
      "P(('all',)|when) = 0.5000\n",
      "P(('at',)|all) = 1.0000\n",
      "P(('once',)|at) = 0.5000\n",
      "P(('i',)|once) = 1.0000\n",
      "P(('saw',)|i) = 0.2000\n",
      "P(('a',)|saw) = 0.5000\n",
      "P(('crowd',)|a) = 0.1429\n",
      "P(('</s>',)|crowd) = 1.0000\n",
      "P(('a',)|<s>) = 0.0833\n",
      "P(('host',)|a) = 0.1429\n",
      "P(('of',)|host) = 1.0000\n",
      "P(('golden',)|of) = 0.3333\n",
      "P(('daffodils',)|golden) = 1.0000\n",
      "P(('</s>',)|daffodils) = 1.0000\n",
      "P(('beside',)|<s>) = 0.0417\n",
      "P(('the',)|beside) = 0.5000\n",
      "P(('lake',)|the) = 0.0909\n",
      "P(('beneath',)|lake) = 1.0000\n",
      "P(('the',)|beneath) = 1.0000\n",
      "P(('trees',)|the) = 0.0909\n",
      "P(('</s>',)|trees) = 1.0000\n",
      "P(('fluttering',)|<s>) = 0.0417\n",
      "P(('and',)|fluttering) = 1.0000\n",
      "P(('dancing',)|and) = 0.1667\n",
      "P(('in',)|dancing) = 1.0000\n",
      "P(('the',)|in) = 0.1429\n",
      "P(('breeze',)|the) = 0.0909\n",
      "P(('</s>',)|breeze) = 1.0000\n",
      "P(('continuous',)|<s>) = 0.0417\n",
      "P(('as',)|continuous) = 1.0000\n",
      "P(('the',)|as) = 0.5000\n",
      "P(('stars',)|the) = 0.0909\n",
      "P(('that',)|stars) = 1.0000\n",
      "P(('shine',)|that) = 0.3333\n",
      "P(('</s>',)|shine) = 1.0000\n",
      "P(('and',)|<s>) = 0.1250\n",
      "P(('twinkle',)|and) = 0.1667\n",
      "P(('on',)|twinkle) = 1.0000\n",
      "P(('the',)|on) = 0.3333\n",
      "P(('milky',)|the) = 0.0909\n",
      "P(('way',)|milky) = 1.0000\n",
      "P(('</s>',)|way) = 1.0000\n",
      "P(('they',)|<s>) = 0.0833\n",
      "P(('stretched',)|they) = 0.3333\n",
      "P(('in',)|stretched) = 1.0000\n",
      "P(('never',)|in) = 0.1429\n",
      "P(('ending',)|never) = 1.0000\n",
      "P(('line',)|ending) = 1.0000\n",
      "P(('</s>',)|line) = 1.0000\n",
      "P(('along',)|<s>) = 0.0417\n",
      "P(('the',)|along) = 1.0000\n",
      "P(('margin',)|the) = 0.0909\n",
      "P(('of',)|margin) = 1.0000\n",
      "P(('a',)|of) = 0.3333\n",
      "P(('bay',)|a) = 0.1429\n",
      "P(('</s>',)|bay) = 1.0000\n",
      "P(('ten',)|<s>) = 0.0417\n",
      "P(('thousand',)|ten) = 1.0000\n",
      "P(('saw',)|thousand) = 1.0000\n",
      "P(('i',)|saw) = 0.5000\n",
      "P(('at',)|i) = 0.2000\n",
      "P(('a',)|at) = 0.5000\n",
      "P(('glance',)|a) = 0.1429\n",
      "P(('</s>',)|glance) = 1.0000\n",
      "P(('tossing',)|<s>) = 0.0417\n",
      "P(('their',)|tossing) = 1.0000\n",
      "P(('heads',)|their) = 1.0000\n",
      "P(('in',)|heads) = 1.0000\n",
      "P(('sprightly',)|in) = 0.1429\n",
      "P(('dance',)|sprightly) = 1.0000\n",
      "P(('</s>',)|dance) = 1.0000\n",
      "P(('the',)|<s>) = 0.0417\n",
      "P(('waves',)|the) = 0.0909\n",
      "P(('beside',)|waves) = 0.5000\n",
      "P(('them',)|beside) = 0.5000\n",
      "P(('danced',)|them) = 1.0000\n",
      "P(('but',)|danced) = 1.0000\n",
      "P(('they',)|but) = 0.3333\n",
      "P(('</s>',)|they) = 0.3333\n",
      "P(('out',)|<s>) = 0.0417\n",
      "P(('did',)|out) = 1.0000\n",
      "P(('the',)|did) = 1.0000\n",
      "P(('sparkling',)|the) = 0.0909\n",
      "P(('waves',)|sparkling) = 1.0000\n",
      "P(('in',)|waves) = 0.5000\n",
      "P(('glee',)|in) = 0.1429\n",
      "P(('</s>',)|glee) = 1.0000\n",
      "P(('a',)|<s>) = 0.0833\n",
      "P(('poet',)|a) = 0.1429\n",
      "P(('could',)|poet) = 1.0000\n",
      "P(('not',)|could) = 1.0000\n",
      "P(('but',)|not) = 1.0000\n",
      "P(('be',)|but) = 0.3333\n",
      "P(('gay',)|be) = 1.0000\n",
      "P(('</s>',)|gay) = 1.0000\n",
      "P(('in',)|<s>) = 0.0833\n",
      "P(('such',)|in) = 0.1429\n",
      "P(('a',)|such) = 1.0000\n",
      "P(('jocund',)|a) = 0.1429\n",
      "P(('company',)|jocund) = 1.0000\n",
      "P(('</s>',)|company) = 1.0000\n",
      "P(('i',)|<s>) = 0.0833\n",
      "P(('gazed',)|i) = 0.2000\n",
      "P(('and',)|gazed) = 0.5000\n",
      "P(('gazed',)|and) = 0.1667\n",
      "P(('but',)|gazed) = 0.5000\n",
      "P(('little',)|but) = 0.3333\n",
      "P(('thought',)|little) = 1.0000\n",
      "P(('</s>',)|thought) = 1.0000\n",
      "P(('what',)|<s>) = 0.0417\n",
      "P(('wealth',)|what) = 1.0000\n",
      "P(('the',)|wealth) = 1.0000\n",
      "P(('show',)|the) = 0.0909\n",
      "P(('to',)|show) = 1.0000\n",
      "P(('me',)|to) = 1.0000\n",
      "P(('had',)|me) = 1.0000\n",
      "P(('brought',)|had) = 1.0000\n",
      "P(('</s>',)|brought) = 1.0000\n",
      "P(('for',)|<s>) = 0.0417\n",
      "P(('oft',)|for) = 1.0000\n",
      "P(('when',)|oft) = 1.0000\n",
      "P(('on',)|when) = 0.5000\n",
      "P(('my',)|on) = 0.3333\n",
      "P(('couch',)|my) = 0.5000\n",
      "P(('i',)|couch) = 1.0000\n",
      "P(('lie',)|i) = 0.2000\n",
      "P(('</s>',)|lie) = 1.0000\n",
      "P(('in',)|<s>) = 0.0833\n",
      "P(('vacant',)|in) = 0.1429\n",
      "P(('or',)|vacant) = 1.0000\n",
      "P(('in',)|or) = 1.0000\n",
      "P(('pensive',)|in) = 0.1429\n",
      "P(('mood',)|pensive) = 1.0000\n",
      "P(('</s>',)|mood) = 1.0000\n",
      "P(('they',)|<s>) = 0.0833\n",
      "P(('flash',)|they) = 0.3333\n",
      "P(('upon',)|flash) = 1.0000\n",
      "P(('that',)|upon) = 1.0000\n",
      "P(('inward',)|that) = 0.3333\n",
      "P(('eye',)|inward) = 1.0000\n",
      "P(('</s>',)|eye) = 1.0000\n",
      "P(('which',)|<s>) = 0.0417\n",
      "P(('is',)|which) = 1.0000\n",
      "P(('the',)|is) = 1.0000\n",
      "P(('bliss',)|the) = 0.0909\n",
      "P(('of',)|bliss) = 1.0000\n",
      "P(('solitude',)|of) = 0.3333\n",
      "P(('</s>',)|solitude) = 1.0000\n",
      "P(('and',)|<s>) = 0.1250\n",
      "P(('then',)|and) = 0.1667\n",
      "P(('my',)|then) = 1.0000\n",
      "P(('heart',)|my) = 0.5000\n",
      "P(('with',)|heart) = 1.0000\n",
      "P(('pleasure',)|with) = 0.5000\n",
      "P(('fills',)|pleasure) = 1.0000\n",
      "P(('</s>',)|fills) = 1.0000\n",
      "P(('and',)|<s>) = 0.1250\n",
      "P(('dances',)|and) = 0.1667\n",
      "P(('with',)|dances) = 1.0000\n",
      "P(('the',)|with) = 0.5000\n",
      "P(('daffodils',)|the) = 0.0909\n",
      "P(('</s>',)|daffodils) = 1.0000\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"I wandered lonely as a cloud\",\n",
    "\"That floats on high o'er vales and hills,\",\n",
    "\"When all at once I saw a crowd,\",\n",
    "\"A host, of golden daffodils;\",\n",
    "\"Beside the lake, beneath the trees,\",\n",
    "\"Fluttering and dancing in the breeze.\",\n",
    "\n",
    "\"Continuous as the stars that shine\",\n",
    "\"And twinkle on the milky way,\",\n",
    "\"They stretched in never-ending line\",\n",
    "\"Along the margin of a bay:\",\n",
    "\"Ten thousand saw I at a glance,\",\n",
    "\"Tossing their heads in sprightly dance.\",\n",
    "\n",
    "\"The waves beside them danced; but they\",\n",
    "\"Out-did the sparkling waves in glee:\",\n",
    "\"A poet could not but be gay,\",\n",
    "\"In such a jocund company:\",\n",
    "\"I gazed—and gazed—but little thought\",\n",
    "\"What wealth the show to me had brought:\",\n",
    "\n",
    "\"For oft, when on my couch I lie\",\n",
    "\"In vacant or in pensive mood,\",\n",
    "\"They flash upon that inward eye\",\n",
    "\"Which is the bliss of solitude;\",\n",
    "\"And then my heart with pleasure fills,\",\n",
    "\"And dances with the daffodils\"]\n",
    "\n",
    "# Preprocess the corpus\n",
    "for i, sent in enumerate(corpus):\n",
    "    # Remove punctuation\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # Add start and end tokens and strip whitespace\n",
    "    corpus[i] = '<s> ' + sent.strip() + ' </s>'\n",
    "\n",
    "# Calculate the unigram and n-gram counts\n",
    "N = 2\n",
    "n_grams = []\n",
    "uni_grams = []\n",
    "for sent in corpus:\n",
    "    tokens = sent.lower().split()\n",
    "    n_grams.extend(list(ngrams(tokens, N)))\n",
    "    uni_grams.extend(tokens)\n",
    "\n",
    "n_gram_count = Counter(n_grams)\n",
    "print(f\"{N}-grams: {n_gram_count}\")\n",
    "uni_gram_count = Counter(uni_grams)\n",
    "print(f\"Uni-grams: {uni_gram_count}\")\n",
    "\n",
    "# Calculate the n-gram probabilities\n",
    "wordsworth_n_gram_probs = {}\n",
    "for n_gram in n_grams:\n",
    "    wordsworth_n_gram_probs[n_gram] = n_gram_count[n_gram] / uni_gram_count[n_gram[0]]\n",
    "    print(f\"P({n_gram[1:]}|{n_gram[0]}) = {wordsworth_n_gram_probs[n_gram]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible tokens: ['i: 0.0833', 'that: 0.0417', 'when: 0.0417', 'a: 0.0833', 'beside: 0.0417', 'fluttering: 0.0417', 'continuous: 0.0417', 'and: 0.1250', 'they: 0.0833', 'along: 0.0417', 'ten: 0.0417', 'tossing: 0.0417', 'the: 0.0417', 'out: 0.0417', 'in: 0.0833', 'what: 0.0417', 'for: 0.0417', 'which: 0.0417']\n",
      "Next token: and\n",
      "\n",
      "Possible tokens: ['hills: 0.1667', 'dancing: 0.1667', 'twinkle: 0.1667', 'gazed: 0.1667', 'then: 0.1667', 'dances: 0.1667']\n",
      "Next token: dances\n",
      "\n",
      "Possible tokens: ['with: 1.0000']\n",
      "Next token: with\n",
      "\n",
      "Possible tokens: ['pleasure: 0.5000', 'the: 0.5000']\n",
      "Next token: pleasure\n",
      "\n",
      "Possible tokens: ['fills: 1.0000']\n",
      "Next token: fills\n",
      "\n",
      "Possible tokens: ['</s>: 1.0000']\n",
      "Next token: </s>\n",
      "\n",
      "Generated text: <s> and dances with pleasure fills </s>\n"
     ]
    }
   ],
   "source": [
    "# Call the function to generate text\n",
    "generated_text = generate_text(wordsworth_n_gram_probs, seed_text='<s>', max_seq_len=10, sampling_method='greedy')\n",
    "print(f'Generated text: {generated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12b9a9f45741c41079d794023550993f",
     "grade": true,
     "grade_id": "cell-3d5b94aaaa651eb2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Test the eager sampling method\n",
    "generated_text = generate_text(n_gram_probs, seed_text='<s>', max_seq_len=10, sampling_method='eager', verbose=False)\n",
    "assert generated_text == '<s> i am sam </s>', f'Generated text: {generated_text}'\n",
    "\n",
    "# Test the random sampling method\n",
    "generated_text = generate_text(n_gram_probs, seed_text='<s>', max_seq_len=10, sampling_method='random', verbose=False)\n",
    "assert generated_text == '<s> i do not like green eggs and ham </s>', f'Generated text: {generated_text}'\n",
    "\n",
    "# Test the weighted random sampling method\n",
    "generated_text = generate_text(n_gram_probs, seed_text='<s>', max_seq_len=10, sampling_method='weighted_random', verbose=False)\n",
    "assert generated_text == '<s> sam i am sam </s>', f'Generated text: {generated_text}'\n",
    "\n",
    "# Test the eager sampling method\n",
    "generated_text = generate_text(wordsworth_n_gram_probs, seed_text='<s>', max_seq_len=10, sampling_method='eager', verbose=False)\n",
    "assert generated_text == '<s> i wandered lonely as a cloud </s>', f'Generated text: {generated_text}'\n",
    "\n",
    "# Test the random sampling method\n",
    "generated_text = generate_text(wordsworth_n_gram_probs, seed_text='<s>', max_seq_len=10, sampling_method='random', verbose=False)\n",
    "assert generated_text == '<s> ten thousand saw a glance </s>', f'Generated text: {generated_text}'\n",
    "\n",
    "# Test the weighted random sampling method\n",
    "generated_text = generate_text(wordsworth_n_gram_probs, seed_text='<s>', max_seq_len=10, sampling_method='weighted_random', verbose=False)\n",
    "assert generated_text == '<s> along the lake beneath the breeze </s>', f'Generated text: {generated_text}'\n",
    "\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c78ca0d4956772a489cc7c97856abf64",
     "grade": false,
     "grade_id": "cell-3c55cde26d4e1670",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color:black\"><h3>Before you submit this notebook to NBGrader for marking:</h3> \n",
    "\n",
    "1. Make sure have completed all exercises marked by <span style=\"color:blue\">**blue cells**</span>.\n",
    "2. For automatically marked exercises ensure you have completed any cells with `# YOUR CODE HERE`. Then click 'Validate' button above, or ensure all cells run without producing an error.\n",
    "3. For manually marked exercises ensure you have completed any cells with `\"YOUR ANSWER HERE\"`.\n",
    "4. Ensure all cells are run with their output visible.\n",
    "5. Fill in your student ID (**only**) below.\n",
    "6. You should now **save and download** your work.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID:** 15006280"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_ai",
   "language": "python",
   "name": "adv_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
