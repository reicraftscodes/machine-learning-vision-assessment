{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3176f19ea3c0c845203029cdfe2c56c",
     "grade": false,
     "grade_id": "cell-ec909e4931ea20ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-danger\" style=\"color:black\"><b>Running ML-LV Jupyter Notebooks:</b><br>\n",
    "    <ol>\n",
    "        <li>Make sure you are running all notebooks using the <code>adv_ai</code> kernel.\n",
    "        <li><b>It is very important that you do not create any additional files within the weekly folders on CSCT cloud.</b> Any additional files, or editing the notebooks with a different environment may prevent submission/marking of your work.</li>\n",
    "            <ul>\n",
    "                <li>NBGrader will automatically fetch and create the correct folders files for you.</li>\n",
    "                <li>All files that are not the Jupyter notebooks should be stored in the 'ML-LV/data' directory.</li>\n",
    "            </ul>\n",
    "        <li>Please <b>do not pip install</b> any python packages (or anything else). You should not need to install anything to complete these notebooks other than the packages provided in the Jupyter CSCT Cloud environment.</li>\n",
    "    </ol>\n",
    "    <b>If you would like to run this notebook locally you should:</b><br>\n",
    "    <ol>\n",
    "        <li>Create an environment using the requirements.txt file provided. <b>Any additional packages you install will not be accessible when uploaded to the server and may prevent marking.</b></li>\n",
    "        <li>Download a copy  of the notebook to your own machine. You can then edit the cells as you wish and then go back and copy the code into/edit the ones on the CSCT cloud in-place.</li>\n",
    "        <li><b>It is very important that you do not re-upload any notebooks that you have edited locally.</b> This is because NBGrader uses cell metadata to track marked tasks. <b>If you change this format it may prevent marking.</b></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "744c758534a391235e7fc42e9873e341",
     "grade": false,
     "grade_id": "cell-e1e88e299de5d5f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\" style=\"color:black\"><h2>3.1 Exercise: Legal and Ethical Considerations for Generative AI</h2>\n",
    "\n",
    "Large Generative language and vision models like GPT, and DALL-E are extremely powerful AI tools. In the last few years, they have received significant coverage in the media, both positive and negative. For example:\n",
    "\n",
    " - [‘A real opportunity’: how ChatGPT could help college applicants](https://www.theguardian.com/education/2023/aug/27/chatgpt-ai-disadvantaged-college-applicants-affirmative-action#:~:text=Chatbots%20can%20suggest%20topics%2C%20offer,to%20do%20on%20their%20own.)\n",
    " \n",
    " - [No major AI model is safe, but some do better than others](https://www.theregister.com/2024/09/17/ai_models_guardrail_feature/?td=keepreading).\n",
    " \n",
    "- [AI helps scholars read scroll buried when Vesuvius erupted in AD79](https://www.theguardian.com/science/2024/feb/05/ai-helps-scholars-read-scroll-buried-when-vesuvius-erupted-in-ad79)\n",
    "\n",
    "- [Google’s hidden AI diversity prompts lead to outcry over historically inaccurate images](https://arstechnica.com/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/)\n",
    "\n",
    "Select **one** legal and/or ethical issue that is directly associated with Large Generative Models. For example: Bias and Mis-information, Discrimination, Copyright and IP, Regulation, Climate and Environment, Socio-economic, etc.\n",
    "\n",
    "Alternatively, you may choose a legal and/or ethical issue that is directly relevant to your group project topic.\n",
    "\n",
    "Briefly describe the selected issue and discuss its implications. Then, use **constructive argument(s)** with regards to the risks and/or benefits, and how these can be addressed in terms of social, political, technical or other practices within the field.\n",
    "\n",
    "This is a short **essay style** question. Your answer should be **no more than 1000 words** and you should back up your writing with some **good quality** references. You should complete your answer in the markdown box below.\n",
    "\n",
    "<table style=\"color:black\">\n",
    "<thead>\n",
    "\n",
    "<tr>\n",
    "<td><p><strong>Percentage Mark/Descriptor</strong></p></td>\n",
    "<td><p><strong>0-49 Inadequate</strong></p></td>\n",
    "<td><p><strong>50-59 Good</strong></p></td>\n",
    "<td><p><strong>60-69 Very Good</strong></p></td>\n",
    "<td><p><strong>70-85 Excellent</strong></p></td>\n",
    "<td><p><strong>86-100 Outstanding</strong></p></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td><p><strong>Discussion (80%)</strong></p></td>\n",
    "<td><p>Legal/ethical issue is only described with little or no reference to chosen problem, risks/benefits and/or how it can be addressed. More than one issue may have been discussed and were not related/relevant.</p></td>\n",
    "\n",
    "<td><p>Basic discussion of legal/ethical issue and with some relevance to a single chosen problem. Limited or no argument(s) for risks/benefits. Proposed solution(s) for addressing the issue are limited and/or too vague/generic.</p></td>\n",
    "\n",
    "<td><p>Good discussion of legal/ethical issue and relevance to a single chosen problem clearly stated and referenced. Some argument(s) for risks/benefits. Proposes concrete solution(s) for addressing the issue.</p></td>\n",
    "\n",
    "<td><p>Excellent discussion of legal/ethical issue and relevance to a single chosen problem clearly stated and referenced. Clear and justified argument(s) for risks/benefits. Proposes concrete solution(s) for addressing the issue.</p></td>\n",
    "\n",
    "<td><p>Extensive and detailed discussion of legal/ethical issue and relevance to a single chosen problem clearly stated and referenced. Strong and justified argument(s) for risks/benefits. Proposes concrete, justified solution(s) for addressing the issue.</p></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td><p><strong>Presentation, Citations & References (20%)</strong></p></td>\n",
    "<td><p>Few/no citation of sources and/or most sources of poor quality or details missing/incomplete.</p></td>\n",
    "<td><p>Some sources cited & listed (1-2); reasonable quality and/or some details missing/incomplete.</p></td>\n",
    "<td><p>Good selection of quality sources (2-3). All sources correctly cited & listed; errors in style or detail only.</p></td>\n",
    "<td><p>Very good selection of quality sources (3-5). All sources correctly cited & listed.</p></td>\n",
    "<td><p>Extensive selection of quality sources (5+). All sources correctly cited & listed.</p></td>\n",
    "</tr>\n",
    "\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<b>MARKS AVAILABLE: 25</b>\n",
    "<br>\n",
    "<b>MO3</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79ebf2b3d328510949ba421cd88b6635",
     "grade": true,
     "grade_id": "cell-cdc88a7a68f3d7e1",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "# Ethical Issues Bias and Discrimination in Facial Emotion Recognition Using YOLO-Based Deep Learning Model for Real-time Applications\n",
    "\n",
    "Facial Emotion Recognition (FER) is a technology that uses deep learning models like YOLO (You Only Look Once) to detect emotions by analysing people’s facial expressions. It is increasingly being applied in real-time settings, without relying on subjective interpretation or self-report. FER can recognise emotions like happiness, sadness, or anger, and could make human-computer interaction more natural and effective. However, using this technology also brings up important ethical concerns, especially around bias and unfair treatment of different demographics.\n",
    "\n",
    "## The Issue of Bias in FER\n",
    "The algorithms powering FER systems are often trained on datasets that may not represent the full diversity of human faces across various demographics, leading to biased outcomes that can adversely affect certain groups. For instance, studies have shown that facial emotion recognition systems are less accurate in identifying emotions in Black individuals compared to White individuals (Buolamwini and Gebru, 2018). This bias can lead to misinterpretation of emotions, resulting in unfair decisions and social inequalities.\n",
    "\n",
    "#### Cultural Background and Masking Conditions\n",
    "\n",
    "Research from Lukac et. al (2023) has shown that facial expression recognition (FER) is significantly influenced by the cultural background of observers and the masking conditions of the target face. A study found that East Asians and Westerners have different perceptions of emotions, with East Asians more likely to interpret \"fear\" as \"surprise\" (Lukac et al., 2023). Masking conditions also significantly affected emotion categorization, with \"fear\" perceived by East Asians for non-masked faces interpreted as \"surprise\" for masked faces (Lukac et al., 2023). This highlights the importance of considering cultural nuances and masking conditions in FER systems due to its highly subjective nature.\n",
    "\n",
    "\n",
    "#### Diversity in Datasets\n",
    "\n",
    "The lack of diversity in datasets is a significant concern in FER technology. For example, AffectNet, a popular dataset for FER tasks (Mahendrakumaran, 2021), has limited accuracy when deployed in the real world due to its lack of cultural diversity, with 64.4% of its training data represented by White subjects. As shown, this lack of diversity can lead to biased outcomes and unfair decisions (Chen, 2024). Prioritising diverse and inclusive datasets during the training phase is essential to ensure that FER systems are fair and unbiased.\n",
    "\n",
    "## Mitigating Bias in FER\n",
    "To reduce bias in Facial Emotion Recognition (FER) systems, it is crucial to prioritise diverse and representative datasets during the training process. This ensures the model encounters a broad range of emotional expressions from various demographic groups, including differences in age, gender, ethnicity, and culture. Companies and developers should also use fairness-aware algorithms that actively work to reduce any disparities in error rates across these groups (Ferrara et al., 2023).\n",
    "\n",
    "Ongoing auditing and testing of the FER system are vital to assess its performance and identify any potential biases, ensuring that the model remains fair and reliable post-deployment. Furthermore, human oversight is essential to provide context and address any biased outputs from the system (Karamotchev, 2024). By applying these practices, the ethical concerns surrounding FER technology can be effectively managed, fostering fairness and accuracy in practical applications.\n",
    "\n",
    "In addition, in the UK, the General Data Protection Regulation (GDPR) is a crucial framework for addressing the ethical concerns surrounding Facial Emotion Recognition (FER) technology. Organisations developing FER systems must prioritise user privacy by employing data anonymisation techniques and following the principle of data minimisation, ensuring that only the necessary data is collected. Additionally, it is essential for FER systems to include clear mechanisms for obtaining user consent, allowing individuals to make informed decisions about how their data will be used. This ensures that users' rights are respected and that their data is handled responsibly within legal guidelines (GDPR Advisor, n.d).\n",
    "\n",
    "\n",
    "#### Benefits of FER technology\n",
    "Despite concerns about bias, the benefits of FER technology are clear. When used correctly, FER systems can enhance human-computer interactions, personalize healthcare, and support mental health professionals. For example, FER can detect early signs of emotional distress, such as anxiety or depression, allowing for timely interventions. As noted in the research by Ferrara (Ferrara, 2023), AI technologies like FER can improve decision-making in sectors such as healthcare, offering better insights into emotional states and enabling more accurate diagnoses and treatments.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "In conclusion, bias and discrimination in facial emotion recognition technology present significant ethical challenges. By ensuring diversity in training data, implementing fairness-aware algorithms, conducting regular audits, and ensuring GDPR compliance, it is possible to mitigate these risks and ensure that FER technology is used ethically and responsibly. The benefits of FER technology are numerous, and with careful consideration of the ethical concerns associated with bias and discrimination, FER systems can be used to enhance human-computer interaction and improve the well-being of individuals.\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "Buolamwini, J. and Gebru, T., (2018) Gender shades: Intersectional accuracy disparities in commercial gender classification. [online] Available at: https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf  [Accessed 15 March 2025].\n",
    "\n",
    "Chen, Y., (2024). Investigating Cross-cultural Generalizability of Facial Emotion Recognition with Multi-dataset Training. University of Twente Student Theses. [online] Available at: https://essay.utwente.nl/100771/1/CHEN_BA_EEMCS.pdf  [Accessed 17 March 2025].\n",
    "\n",
    "Ferrara, C., Sellitto, G., Ferrucci, F., Palomba, F. and De Lucia, A., (2023). Fairness-aware machine learning engineering: how far are we? [online] Empirical Software Engineering, 28(6), pp.1–30. Available at: https://link.springer.com/article/10.1007/s10664-023-10402-y  [Accessed 21 Apr. 2025].\n",
    "\n",
    "Ferrara, E., 2023. Fairness and Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, and Mitigation Strategies. [online] Available at: https://www.researchgate.net/publication/376848202_Fairness_and_Bias_in_Artificial_Intelligence_A_Brief_Survey_of_Sources_Impacts_and_Mitigation_Strategies  [Accessed 08 April 2025].\n",
    "\n",
    "Lukac, M., Zhambulova, G., Abdiyeva, K. and Lewis, M., (2023). Study on emotion recognition bias in different regional groups. [online] PubMed Central (PMC). Available at: https://pmc.ncbi.nlm.nih.gov/articles/PMC10209154/  [Accessed 6 April. 2025].\n",
    "\n",
    "Mahendrakumaran, K., (2021) Emotion Recognition Datasets. Analytics Vidhya. [online] Available at: https://medium.com/analytics-vidhya/emotion-recognition-datasets-8a397590c7d1  [Accessed 12 March 2025].\n",
    "\n",
    "Nagata, M. and Okajima, K., (2023) Effect of observer’s cultural background and masking condition of target face on facial expression recognition for machine-learning dataset. PLOS ONE, [online] Available at: https://doi.org/10.1371/journal.pone.0280515  [Accessed 22 April 2025].\n",
    "\n",
    "Karamotchev, P., (2024). AI System Bias Audit: Is This Even Possible? Understanding and Addressing the Challenges of Ensuring Fairness in AI Systems. [online] Medium. Available at: https://medium.com/industria-tech/ai-system-bias-audit-is-this-even-possible-ef2b53dac2fe  [Accessed 22 April 2025]\n",
    "\n",
    "Raji, I.D., Gebru, T., Mitchell, M., Buolamwini, J., Lee, J. and Smith, E., (2020) Saving Face: Investigating the Ethical Concerns of Facial Recognition Auditing. In: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. [online] Available at: https://dl.acm.org/doi/10.1145/3375627.3375820 [Accessed 20 April 2025].\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60afcf14490ec3492eaff1d217f50561",
     "grade": false,
     "grade_id": "cell-f8c4c4505ff51045",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color:black\"><h3>Before you submit this notebook to NBGrader for marking:</h3> \n",
    "\n",
    "1. Make sure have completed all exercises marked by <span style=\"color:blue\">**blue cells**</span>.\n",
    "2. For automatically marked exercises ensure you have completed any cells with `# YOUR CODE HERE`. Then click 'Validate' button above, or ensure all cells run without producing an error.\n",
    "3. For manually marked exercises ensure you have completed any cells with `\"YOUR ANSWER HERE\"`.\n",
    "4. Ensure all cells are run with their output visible.\n",
    "5. Fill in your student ID (**only**) below.\n",
    "6. You should now **save and download** your work.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID: 15006280** \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
